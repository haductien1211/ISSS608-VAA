{
  "hash": "4de267fb8ac3b286193eff5e286e344d",
  "result": {
    "markdown": "---\ntitle: \"In-class Exercise 5\"\nauthor: \"Ha Duc Tien\"\ndate: \"May 11, 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n---\n\n\n# 1. Loading R Packages for text data processing\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, readtext, quanteda, tidytext)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npackage 'bitops' successfully unpacked and MD5 sums checked\npackage 'qpdf' successfully unpacked and MD5 sums checked\npackage 'minty' successfully unpacked and MD5 sums checked\npackage 'RCurl' successfully unpacked and MD5 sums checked\npackage 'rjson' successfully unpacked and MD5 sums checked\npackage 'ndjson' successfully unpacked and MD5 sums checked\npackage 'antiword' successfully unpacked and MD5 sums checked\npackage 'pdftools' successfully unpacked and MD5 sums checked\npackage 'readODS' successfully unpacked and MD5 sums checked\npackage 'streamR' successfully unpacked and MD5 sums checked\npackage 'striprtf' successfully unpacked and MD5 sums checked\npackage 'readtext' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n\tC:\\Users\\tien_\\AppData\\Local\\Temp\\Rtmp4avxRY\\downloaded_packages\npackage 'ISOcodes' successfully unpacked and MD5 sums checked\npackage 'fastmatch' successfully unpacked and MD5 sums checked\npackage 'stopwords' successfully unpacked and MD5 sums checked\npackage 'quanteda' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n\tC:\\Users\\tien_\\AppData\\Local\\Temp\\Rtmp4avxRY\\downloaded_packages\n```\n:::\n:::\n\n\n# 2. Loading the text data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntext_data <- readtext(\"data/articles/*\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncorpus_text <- corpus(text_data)\n\nsummary(corpus_text, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 338 documents, showing 5 documents:\n\n                                   Text Types Tokens Sentences\n Alvarez PLC__0__0__Haacklee Herald.txt   206    433        18\n    Alvarez PLC__0__0__Lomark Daily.txt   102    170        12\n   Alvarez PLC__0__0__The News Buoy.txt    90    200         9\n Alvarez PLC__0__1__Haacklee Herald.txt    96    187         8\n    Alvarez PLC__0__1__Lomark Daily.txt   241    504        21\n```\n:::\n:::\n\n\n# 3. Some Text Data Processing\n\n\n::: {.cell}\n\n```{.r .cell-code}\nusenet_words <- text_data %>%\n  unnest_tokens(word, text) %>%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nview(usenet_words)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nusenet_words %>%\n  count(word, sort = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nreadtext object consisting of 3260 documents and 0 docvars.\n# A data frame: 3,260 × 3\n  word             n text     \n  <chr>        <int> <chr>    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,254 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntext_data_splitted <- text_data %>%\n  separate_wider_delim(\"doc_id\",\n                        delim = \"__0__\",\n                        names = c(\"X\",\"Y\"),\n                        too_few = \"align_end\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nview(text_data_splitted)\n```\n:::\n\n\n# 4. Loading R packages for json data processing\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(jsonlite, tidyverse)\n```\n:::\n\n\n# 5. Loading the json data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc1_data <- fromJSON(\"data/mc1.json\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}