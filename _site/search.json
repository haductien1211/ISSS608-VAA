[
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "The Oceanus business ecosystem is dynamic in nature, marked by the continual emergence of startups, mergers, acquisitions, and investments. FishEye International serves as a vigilant overseer of this landscape, meticulously monitoring the activities of commercial fishing operators to uphold the integrity of the region’s marine ecosystem. Through comprehensive analysis of business records, FishEye endeavors to uncover ownership structures, shareholder dynamics, transactional histories, and the core offerings of each entity, culminating in the creation of CatchNet: the Oceanus Knowledge Graph, achieved through a blend of automated processes and manual review.\nRecent events have cast a shadow over Oceanus’s commercial fishing sector, following the discovery of illegal fishing practices by SouthSeafood Express Corp. In response, FishEye has initiated an in-depth exploration to discern the temporal implications of this occurrence on Oceanus’s fishing marketplace. The competitive landscape may witness a variety of reactions, ranging from aggressive maneuvers by industry players seeking to capitalize on voids left by SouthSeafood Express Corp, to a heightened awareness within the industry that unlawful activities will be met with diligent scrutiny and consequential action. This ongoing investigation underscores the significance of FishEye’s role in maintaining the ethical and legal standards of Oceanus’s commercial endeavors.\n\n\nWith reference to the Mini-Challenge 3 of VAST Challenge 2024.\nA key element in stopping illegal fishing is holding the people who own nefarious companies accountable. Thus, FishEye is keenly interested in developing visualization tools that work with CatchNet to identify the people who hold influence over business networks. That is especially difficult with varied and changing shareholder and ownership relationships. My main focus for this portion would be on:\nCreate a visual analytics approach that analysts can use to highlight temporal patterns and changes in corporate structures. Examine the most active people and businesses using visual analytics.\nBelow is a further clarification from organizer\n\n\n\n\n\n\n1. What level of corporate change is of interest?\n\n\n\nQuestion\nDoes the concept of ‘changes in corporate structures over time’ mean the changes in one corporation,like the changes of board of the company, or the changes happening in the whole society, like the ratio of some kind of companies?\nClarification\nFishEye is more interested in the ways in which the structures of individual corporations change over time, rather than macro-economic or industry-level changes in the Oceanus marketplace. In some cases the corporate structure of several organizations may be intertwined (such as when one company owns another) and the relationships between them would therefore be relevant. Systematic trends in the ways individual companies re-structure over time could also be interesting. However, any large-scale changes in the structure of the economy are not the intention.\n\n\nSo it looks like being to show the changes over time is important\n\n\n\nThe data used for this part would be the mc3.json file download from the VAST MC3 website"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Assuming the role of a graphical editor of a median company, the purpose of this data visualization exercise is to prepare minimum two and maximum three data visualizations to reveal interesting insights on the private residential market and sub-markets of Singapore for the 1st quarter of 2024 and prior periods.\n\n\n\nFor this exercise and to accomplish the task, transaction data of REALIS will be used, which provides comprehensive and up-to-date statistics on the property market in Singapore.\nA complete set of the private residential property transaction data from 1st January 2023 to 31st March 2024"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-task",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Assuming the role of a graphical editor of a median company, the purpose of this data visualization exercise is to prepare minimum two and maximum three data visualizations to reveal interesting insights on the private residential market and sub-markets of Singapore for the 1st quarter of 2024 and prior periods."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "For this exercise and to accomplish the task, transaction data of REALIS will be used, which provides comprehensive and up-to-date statistics on the property market in Singapore.\nA complete set of the private residential property transaction data from 1st January 2023 to 31st March 2024"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-the-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-the-packages",
    "title": "Take-home Exercise 1",
    "section": "2.1 Loading the packages",
    "text": "2.1 Loading the packages\nFor this Take-home exercise 1, I am planning to use some of the libraries below:\ntidyverse: The tidyverse is an opinionated collection of R packages designed for data science.\npatchwork: a package to make it simple to combine separate ggplots into the same graphic\nggrepel: a package to provide geoms for ggplot2 to repel overlapping text labels\nggthemes: a package to provide some extra themes, geoms, and scales for ‘ggplot2’.\nggridges: a package for Ridgeline plots, which are partially overlapping line plots that create the impression of a mountain range.\nggdist: an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualizing distributions and uncertainty which will assist with ggridges package\n\nThe Code:\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggridges, ggdist)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-data-and-preparation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-data-and-preparation",
    "title": "Take-home Exercise 1",
    "section": "2.2 Importing data and preparation",
    "text": "2.2 Importing data and preparation\nSince the data is a list of csv files containing quarterly data from the first quarter of 2023 to the first quarter of 2024, for the purpose of the study I will be creating and using both the full data set (Realis) and a smaller data set containing only data for the first quarter of 2024 (first_quarter_2024) from ResidentialTransaction20240414220633.csv file\n\nThe Code:\n\nfirst_quarter_2024 &lt;- read_csv(\"data/ResidentialTransaction20240414220633.csv\")\n\nlist_of_files &lt;- list.files(path = \"data\",\n                            recursive = TRUE,\n                            pattern = \"\\\\.csv$\",\n                            full.names = TRUE)\nRealis &lt;- read_csv(list_of_files)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-overview",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-overview",
    "title": "Take-home Exercise 1",
    "section": "3.1 Data overview",
    "text": "3.1 Data overview\n\nThe Code:\n\nglimpse(Realis)\n\nRows: 26,806\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\nsummary(Realis)\n\n Project Name       Transacted Price ($)  Area (SQFT)       Unit Price ($ PSF)\n Length:26806       Min.   :   440000    Min.   :   322.9   Min.   : 138      \n Class :character   1st Qu.:  1280000    1st Qu.:   721.2   1st Qu.:1384      \n Mode  :character   Median :  1660000    Median :   990.3   Median :1762      \n                    Mean   :  2143286    Mean   :  1191.6   Mean   :1852      \n                    3rd Qu.:  2320000    3rd Qu.:  1302.4   3rd Qu.:2260      \n                    Max.   :392180000    Max.   :144883.4   Max.   :5756      \n  Sale Date           Address          Type of Sale       Type of Area      \n Length:26806       Length:26806       Length:26806       Length:26806      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   Area (SQM)      Unit Price ($ PSM) Nett Price($)      Property Type     \n Min.   :   30.0   Min.   : 1484      Length:26806       Length:26806      \n 1st Qu.:   67.0   1st Qu.:14893      Class :character   Class :character  \n Median :   92.0   Median :18966      Mode  :character   Mode  :character  \n Mean   :  110.7   Mean   :19930                                           \n 3rd Qu.:  121.0   3rd Qu.:24327                                           \n Max.   :13460.0   Max.   :61962                                           \n Number of Units     Tenure          Completion Date   \n Min.   : 1.000   Length:26806       Length:26806      \n 1st Qu.: 1.000   Class :character   Class :character  \n Median : 1.000   Mode  :character   Mode  :character  \n Mean   : 1.005                                        \n 3rd Qu.: 1.000                                        \n Max.   :60.000                                        \n Purchaser Address Indicator Postal Code        Postal District   \n Length:26806                Length:26806       Length:26806      \n Class :character            Class :character   Class :character  \n Mode  :character            Mode  :character   Mode  :character  \n                                                                  \n                                                                  \n                                                                  \n Postal Sector      Planning Region    Planning Area     \n Length:26806       Length:26806       Length:26806      \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n\ncolSums(is.na(Realis))\n\n               Project Name        Transacted Price ($) \n                          0                           0 \n                Area (SQFT)          Unit Price ($ PSF) \n                          0                           0 \n                  Sale Date                     Address \n                          0                           0 \n               Type of Sale                Type of Area \n                          0                           0 \n                 Area (SQM)          Unit Price ($ PSM) \n                          0                           0 \n              Nett Price($)               Property Type \n                          0                           0 \n            Number of Units                      Tenure \n                          0                           0 \n            Completion Date Purchaser Address Indicator \n                          0                           0 \n                Postal Code             Postal District \n                          0                           0 \n              Postal Sector             Planning Region \n                          0                           0 \n              Planning Area \n                          0 \n\n\nA quick look at the data shown that there are 21 different columns, there are categorical variables that could be of interest such as Project Name, Property Type, Planning Region, Planning Area as well as continuous variables such as Transacted Price ($), Area (SQFT), Area (SQM), Unit Price ($ PSF), Unit Price ($ PSM), Number of Units.\nThere is also no missing data which is good and mean that we do not have to perform data wrangling for missing data.\nFor the purpose of this study, I would be focusing on these variable below:\nProperty Type, Planning Region, Transacted Price ($), Area (SQM), Unit Price ($ PSM), Sale Date"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take-home Exercise 1",
    "section": "3.2 Data wrangling",
    "text": "3.2 Data wrangling\nInterestingly, Sale Date is supposed to be a kind of continuous variable or discrete variable; however, it is in ‘character’ type instead of ‘datetime’ or rather it is just in ‘string’, even though, the format seems correct. In addition, I also want to use a sort of monthly data visualization and the time seems to be in Date format.\nTherefore some data transformation would need to be performed to create 2 new column called Sale Date asDate which is properly in Datetime format, and Sale Month, which show the month Sale happened instead of date.\nTo do this I would be using parse_date_time part of the lubridate in tidyverse package to correctly pasring the ‘string’ into datetime format then use as.Date to finally turn it into proper ‘datetime’, this would also create the Sale Date asDate column.\nAfter above steps, I will be using format to create the Sale Month colum\n\nThe Code:\n\nRealis &lt;- Realis %&gt;% \n  mutate(`Sale Date asDate` = as.Date((parse_date_time(`Sale Date`, \n        orders = c(\"%d %b %Y\")))))\nRealis &lt;- Realis %&gt;% \n  mutate(`Sale Month` = format(as.Date((parse_date_time(`Sale Date`, \n        orders = c(\"%d %b %Y\")))), \"%b %Y\"))\n\n\n\nfirst_quarter_2024 &lt;- first_quarter_2024 %&gt;% \n  mutate(`Sale Date asDate` = as.Date((parse_date_time(`Sale Date`, \n        orders = c(\"%d %b %Y\")))))\n\nfirst_quarter_2024 &lt;- first_quarter_2024 %&gt;% \n  mutate(`Sale Month` = format(as.Date((parse_date_time(`Sale Date`, \n        orders = c(\"%d %b %Y\")))), \"%b %Y\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-visualization-for-the-first-quarter-of-2024",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-visualization-for-the-first-quarter-of-2024",
    "title": "Take-home Exercise 1",
    "section": "4.1 Data visualization for the first quarter of 2024",
    "text": "4.1 Data visualization for the first quarter of 2024\n\n4.1.1 Main part\nThis part of the first quarter of 2024 data visualization contain 3 plots:\n\nOn the left is the bar plot counting the number of sales breaking down by different Planning Region\nOn the right is a ridgeline plot showing the Unit Price ($ PSM) distribution breakdown by 4 quartiles by different Planning Region\nBottom plot is box plot showing a further breakdown from the ridgeline plot going into different Property Type\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\nplot1 &lt;-ggplot(data = first_quarter_2024, aes(x = `Planning Region`)) +\n    geom_bar(color = \"grey10\", aes(fill = `Property Type`)) +\n    ggtitle(\"Sales by Property Type by Planning Region\") +\n    theme_economist() +\n    theme(axis.text=element_text(size = 20), \n          axis.title = element_text(size = 25), \n          title = element_text(size = 25, margin = margin(b = 15)), \n          axis.title.y = element_text(margin = margin(r = 15)),\n          axis.title.x = element_text(margin = margin(t = 15)))\n\nplot2 &lt;- ggplot(data = first_quarter_2024, aes(x = `Planning Region`, y = `Unit Price ($ PSM)`)) +\n    geom_boxplot(aes(color=`Property Type`)) + \n    theme(axis.text=element_text(size=12)) +\n    ggtitle(\"Distribution of Unit Price ($ PSM) by Planning Region by Property Type\")+\n    theme_economist() +\n    theme(axis.text=element_text(size = 20), \n          axis.title = element_text(size = 25), \n          title = element_text(size = 25, margin = margin(b = 15)), \n          axis.title.y = element_text(margin = margin(r = 15)),\n          axis.title.x = element_text(margin = margin(t = 15)))\n\nplot3 &lt;- ggplot(data = first_quarter_2024, \n       aes(y = `Planning Region`, x = `Unit Price ($ PSM)`, \n            fill = factor(after_stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_economist()+\n  ggtitle(\"Distribution of Unit Price ($ PSM) by Planning Region\")+\n  theme(axis.text=element_text(size = 20), \n        axis.title = element_text(size = 25), \n        title = element_text(size = 25, margin = margin(b = 15)), \n        axis.title.y = element_text(margin = margin(r = 15)),\n        axis.title.x = element_text(margin = margin(t = 15)))\n\n(plot1 + plot3 ) / plot2\n\n\n\n\n\n\n\n\n\n\nObservations and insights\n\n\n\nFrom the data visualizations above, here are my observations and insights on date from first quarter 2024:\n\nThe Central region seems to have the highest number of sales followed by the North East region with main Property Type being Apartment and Condominium. North Region has the lowest number of sales, but their main Property Type sale is Executive Condominium; similarly West Region main Property Type sale is also Executive Condominium\nThe Unit Price ($ PSM) seems to be on average higher in the Central and North East region with some of the highest being in Central region\nFurther breakdown of Unit Price ($ PSM) by Property Type show an interesting trend of Apartment being more expensive than other types in Central and North East region. Meanwhile, in North and West region where their main Property Type sale is Executive Condominium the Unit Price ($ PSM) is lowest.\n\n\n\n\n\n4.1.1 Sub part\nFor this sub part, I am showing a scatterplot of Area (SQM) vs Transacted Price ($), with a fit line using Generalized Linear Models, each data point is label under their Planning Region and different colors is for different Property Type.\nThe purpose of this plot is to see if there is a relationship between property size and its price as well as to see which property type from which region is likely to be of bigger size and more expensive overall.\nHowever, since the proper size and its transacted price could be quite high (144883.4 SQM for size and 392,180,000 SGD for price), for this study, I have limited the data to be within 30 - 600 SQM for size and 450,000 - 10,000,000 SGD for transacted price\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\nggplot(data = first_quarter_2024, aes(y = `Area (SQM)`,\n                                      x = `Transacted Price ($)`)) +\n  geom_point()+\n  geom_smooth(method = glm, linewidth = 1) +\n  coord_cartesian(ylim = c(30,600), xlim=c(450000,10000000)) +\n  geom_label_repel(aes(label = `Planning Region`, color = `Property Type`), \n                   fontface = \"bold\", max.overlaps = 12) +\n  ggtitle(\"Size (SQM) vs Transacted Price ($) in the first quarter of 2024\") +\n  theme_economist()+\n  theme(axis.text=element_text(size = 15), \n        axis.title = element_text(size = 20), \n        title = element_text(size = 20, margin = margin(b = 15)), \n        axis.title.y = element_text(margin = margin(r = 15)),\n        axis.title.x = element_text(margin = margin(t = 15)))\n\n\n\n\n\n\n\n\n\n\nObservations and insights\n\n\n\nFrom the data visualizations above, here are my observations\n\nThere seems to be a clear linear correlation between Area (SQM) and Transacted Price ($) based on the Generalized Linear Models fit line.\nCentral region shows a high concentration of high value properties with some of the most expensive properties and these properties are mainly Condominium and Executive Condominium.\nDetached House seems to be generally larger than other types of property."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#time-series-data-visualization-from-2023-to-first-quarter-of-2024",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#time-series-data-visualization-from-2023-to-first-quarter-of-2024",
    "title": "Take-home Exercise 1",
    "section": "4.2 Time series data visualization from 2023 to first quarter of 2024",
    "text": "4.2 Time series data visualization from 2023 to first quarter of 2024\nThis part of the data visualization contain 3 plots:\n\nOn the top is a bar plot, counting the number of monthly sales breaking down by different Property Type\nIn the middle is a box plot showing the monthly distribution of Unit Price ($ PSM) by different Property Type\nBottom plot is a line plot as further breakdown from the middle box plot, showing the movement of Mean Unit Price ($ PSM) by different Property Type\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\nplot4 &lt;- ggplot(data = Realis, aes(x = `Sale Month`)) +\n    geom_bar(color = \"grey10\", aes(fill = `Property Type`)) +\n    scale_x_discrete(name =\"Sale Month\", \n                     limits = c(\"Jan 2023\", \"Feb 2023\", \"Mar 2023\", \n                        \"Apr 2023\",\"May 2023\",\"Jun 2023\", \n                        \"Jul 2023\", \"Aug 2023\", \"Sep 2023\",\n                        \"Oct 2023\", \"Nov 2023\", \"Dec 2023\", \n                        \"Jan 2024\", \"Feb 2024\", \"Mar 2024\")) +\n  \n    ggtitle(\"Monthly number of sales by Property Type\") +\n    theme_economist() +\n    theme(axis.text=element_text(size = 15), \n          axis.title = element_text(size = 18)\n          , title = element_text(size = 20), axis)\n\nplot5 &lt;- ggplot(data = Realis, aes(x = `Sale Month`, y = `Unit Price ($ PSM)`)) +\n    scale_x_discrete(name =\"Sale Month\",\n                   limits = c(\"Jan 2023\", \"Feb 2023\", \"Mar 2023\",\n                      \"Apr 2023\",\"May 2023\",\"Jun 2023\",\n                      \"Jul 2023\", \"Aug 2023\", \"Sep 2023\",\n                      \"Oct 2023\", \"Nov 2023\", \"Dec 2023\",\n                      \"Jan 2024\", \"Feb 2024\", \"Mar 2024\")) +\n    \n    geom_boxplot(aes(color=`Property Type`)) + \n    theme(axis.text=element_text(size=12)) +\n    ggtitle(\"Monthly changes in Unit Price ($PSM)\")+\n    theme_economist() +\n    theme(axis.text=element_text(size = 15), \n          axis.title = element_text(size = 18)\n          , title = element_text(size = 20))\n\nby_month &lt;- Realis %&gt;%\n  group_by(`Property Type`, `Sale Month`) %&gt;%\n  summarise(`Mean Unit Price ($ PSM)` = mean(`Unit Price ($ PSM)`))\n\nby_month$`Sale Month` &lt;- factor(by_month$`Sale Month`, \n                                levels = c(\"Jan 2023\", \"Feb 2023\", \"Mar 2023\",\n                                            \"Apr 2023\",\"May 2023\",\"Jun 2023\",\n                                            \"Jul 2023\", \"Aug 2023\", \"Sep 2023\",\n                                            \"Oct 2023\", \"Nov 2023\", \"Dec 2023\",\n                                            \"Jan 2024\", \"Feb 2024\", \"Mar 2024\"))\n\nby_month &lt;- by_month[order(by_month$`Sale Month`),]\n\n\nplot6 &lt;- ggplot(data = by_month, aes(x = `Sale Month`, y = `Mean Unit Price ($ PSM)`, \n                            group = `Property Type`)) +\n    geom_path(aes(color = `Property Type`), size = 1) +\n    geom_point(size = 1.5) +\n    theme(axis.text=element_text(size=12))+\n    ggtitle(\"Monthly changes in Mean Unit Price ($PSM) 2023 to first quarter 2024\")+\n    theme_economist() +\n    theme(axis.text=element_text(size = 15), \n        axis.title = element_text(size = 18)\n        , title = element_text(size = 20))\n\n(plot4 / plot5 / plot6)\n\n\n\n\n\n\n\n\n\n\nObservations and insights\n\n\n\nFrom the data visualizations above, here are my observations:\n\nThe main property types for sales from Jan 2023 to Mar 2024 seem to be Apartment and Condominium followed by Executive Condominium. The highest sales amount for this period occurred in July 2023\nThe overall Unit Price ($ PSM) for different property type during the period seems stable except for Detached House which has a dip in July 2023 and Executive Condominium with overall downward trend and a dip in Jun 2023. For Apartment type, there seems to be an overall downward trend for Mean Unit Price ($ PSM) but seems to be picking up again\nSurprisingly, contrary to what being observed in the scatterplot where some of the most expensive properties are Executive Condominium, their overall Mean Unit Price ($ PSM) has been the lowest and quite stable, albeit there is a small increase starting 2024"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-Class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-Class_Ex05.html",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "1. Loading R Packages for text data processing\n\npacman::p_load(tidyverse, readtext, quanteda, tidytext)\n\npackage 'bitops' successfully unpacked and MD5 sums checked\npackage 'qpdf' successfully unpacked and MD5 sums checked\npackage 'minty' successfully unpacked and MD5 sums checked\npackage 'RCurl' successfully unpacked and MD5 sums checked\npackage 'rjson' successfully unpacked and MD5 sums checked\npackage 'ndjson' successfully unpacked and MD5 sums checked\npackage 'antiword' successfully unpacked and MD5 sums checked\npackage 'pdftools' successfully unpacked and MD5 sums checked\npackage 'readODS' successfully unpacked and MD5 sums checked\npackage 'streamR' successfully unpacked and MD5 sums checked\npackage 'striprtf' successfully unpacked and MD5 sums checked\npackage 'readtext' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\tien_\\AppData\\Local\\Temp\\Rtmp4avxRY\\downloaded_packages\npackage 'ISOcodes' successfully unpacked and MD5 sums checked\npackage 'fastmatch' successfully unpacked and MD5 sums checked\npackage 'stopwords' successfully unpacked and MD5 sums checked\npackage 'quanteda' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\tien_\\AppData\\Local\\Temp\\Rtmp4avxRY\\downloaded_packages\n\n\n\n\n2. Loading the text data\n\ntext_data &lt;- readtext(\"data/articles/*\")\n\n\ncorpus_text &lt;- corpus(text_data)\n\nsummary(corpus_text, 5)\n\nCorpus consisting of 338 documents, showing 5 documents:\n\n                                   Text Types Tokens Sentences\n Alvarez PLC__0__0__Haacklee Herald.txt   206    433        18\n    Alvarez PLC__0__0__Lomark Daily.txt   102    170        12\n   Alvarez PLC__0__0__The News Buoy.txt    90    200         9\n Alvarez PLC__0__1__Haacklee Herald.txt    96    187         8\n    Alvarez PLC__0__1__Lomark Daily.txt   241    504        21\n\n\n\n\n3. Some Text Data Processing\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nview(usenet_words)\n\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3260 documents and 0 docvars.\n# A data frame: 3,260 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,254 more rows\n\n\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                        delim = \"__0__\",\n                        names = c(\"X\",\"Y\"),\n                        too_few = \"align_end\")\n\n\nview(text_data_splitted)\n\n\n\n4. Loading R packages for json data processing\n\npacman::p_load(jsonlite, tidyverse)\n\n\n\n5. Loading the json data\n\nmc1_data &lt;- fromJSON(\"data/mc1.json\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "#Getting Started ## Loading R packages"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-data",
    "title": "In-class Exercise 2",
    "section": "Importing the data",
    "text": "Importing the data\n\nexam_df &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution",
    "title": "In-class Exercise 2",
    "section": "Visualising Distribution",
    "text": "Visualising Distribution\n\nHistogram\n\nggplot(exam_df, aes(x=ENGLISH))+\n  geom_histogram(bins = 20, color = \"grey10\", fill = \"lightblue\")\n\n\n\n\n\n\nThe alternative Design\n\nggplot(exam_df, aes(x=ENGLISH))+\n  geom_density(color = \"#1696d2\", adjust = 0.65, alpha = 0.6)\n\n\n\n\n\nmedian_eng &lt;- median(exam_df$ENGLISH)\nmean_eng &lt;- mean(exam_df$ENGLISH)\nstd_eng &lt;- sd(exam_df$ENGLISH)\n\nggplot(exam_df, aes(x=ENGLISH))+\n  geom_density(color = \"#1696d2\", adjust = 0.65, alpha = 0.6) +\n  geom_vline(aes(xintercept = mean_eng), colour = \"#4d5887\", linewidth = 0.6, linetype = \"dashed\")\n\n\n\n  # annotate(geom = \"text\", x = mean_eng - 8, y = 0.04 label = paste0(\"Mean ENGLISH: \", round((mean_eng),2)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html",
    "title": "Hands-on Exercise 8.3 Analytical Mapping",
    "section": "",
    "text": "In this in-class exercise, we will gain hands-on experience on using appropriate R methods to plot analytical maps.\nBy the end of this in-class exercise, we will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#installing-and-loading-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 8.3 Analytical Mapping",
    "section": "2.1 Installing and loading packages",
    "text": "2.1 Installing and loading packages\nInstall and load sf, tmap and tidyverse packages into R environment.\n\npacman::p_load(tmap, tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#importing-data",
    "title": "Hands-on Exercise 8.3 Analytical Mapping",
    "section": "2.2 Importing data",
    "text": "2.2 Importing data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#visualising-distribution-of-non-functional-water-point",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#visualising-distribution-of-non-functional-water-point",
    "title": "Hands-on Exercise 8.3 Analytical Mapping",
    "section": "Visualising distribution of non-functional water point",
    "text": "Visualising distribution of non-functional water point\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "title": "Hands-on Exercise 8.3 Analytical Mapping",
    "section": "4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points",
    "text": "4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#plotting-map-of-rate",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#plotting-map-of-rate",
    "title": "Hands-on Exercise 8.3 Analytical Mapping",
    "section": "4.2 Plotting map of rate",
    "text": "4.2 Plotting map of rate\nPlot a choropleth map showing the distribution of percentage functional water point by LGA\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#percentile-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#percentile-map",
    "title": "Hands-on Exercise 8.3 Analytical Mapping",
    "section": "5.1 Percentile Map",
    "text": "5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n5.1.1 Data Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n5.1.2 Why writing functions?\nWriting a function has three big advantages over using copy-and-paste:\nYou can give a function an evocative name that makes your code easier to understand. As requirements change, you only need to update code in one place, instead of many. You eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\nSource: Chapter 19: Functions of R for Data Science.\n\n\n5.1.3 Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n  vname: variable name (as character, in quotes)\n  df: name of sf data frame\nreturns:\n  v: vector with values (without a column name)\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n5.1.4 A percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n5.1.5 Test drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#box-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#box-map",
    "title": "Hands-on Exercise 8.3 Analytical Mapping",
    "section": "5.2 Box map",
    "text": "5.2 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n5.2.1 Creating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n  v: vector with observations\n  mult: multiplier for IQR (default 1.5)\nreturns:\n  bb: vector with 7 break points compute quartile and fences\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n5.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n  vname: variable name (as character, in quotes)\n  df: name of sf data frame\nreturns:\n  v: vector with values (without a column name)\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n5.2.3 Test drive the newly created function\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n5.2.4 Boxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, we will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#installing-an-loading-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#installing-an-loading-packages",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "2.1 Installing an loading packages",
    "text": "2.1 Installing an loading packages\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data. Among the four packages, readr, tidyr and dplyr are part of tidyverse package.\n\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#importing-data-into-r",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "2.2 Importing Data into R",
    "text": "2.2 Importing Data into R\n\n2.2.1 The Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n2.2.2 Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\tien_\\OneDrive\\SMU\\ISSS608-Visual Analytics and Applications\\haductien1211\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n2.2.3 Importing Attribute Data into R\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n2.2.4 Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\nData wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6]) + rowSums(.[12])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) + rowSums(.[13:15]))%&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`,\n         `ECONOMY ACTIVE`, `AGED`,\n         `TOTAL`, `DEPENDENCY`)\n\n\n\nJoining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n            .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, \n                          popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\n\n\n\nTip\n\n\n\n##Thing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "3.1 Plotting a choropleth map quickly by using qtm()",
    "text": "3.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n##Thing to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "3.2 Creating a choropleth map by using tmap’s elements",
    "text": "3.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n3.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n3.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n##Thing to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section.\nBy default, Missing value will be shaded in grey.\n\n\n\n\n\n3.2.3 Drawing a choropleth map using tm_fill() and tm_border()\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour.\nlwd = border line width, the default is 1.\nlty = border line type. The default is “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "3.3 Data classification methods of tmap",
    "text": "3.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n3.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\nWarning: Maps Lie!\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nDifferent numbers of n (i.e. 2, 6, 10, 20) show that certain classification may not be effective in showing choropleth maps\n\n\n3.3.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#colour-scheme",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "3.4 Colour Scheme",
    "text": "3.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n3.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the colour scheme has been reversed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#map-layouts",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "3.5 Map Layouts",
    "text": "3.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n3.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \n            (Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n3.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n3.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \n            by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from \n             Urban Redevelopment Authorithy (URA)\n             and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "3.6 Drawing Small Multiple Choropleth Maps",
    "text": "3.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the aesthetic arguments,\nby defining a group-by variable in tm_facets().\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n3.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n3.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n3.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#mappping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#mappping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "3.7 Mappping Spatial Object Meeting a Selection Criterion",
    "text": "3.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#all-about-tmap-package",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "4.1 All about tmap package",
    "text": "4.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "4.2 Geospatial data wrangling",
    "text": "4.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.1.html#data-wrangling-1",
    "title": "Hands-on Exercise 8.1 Visualising Geospatial Point Data",
    "section": "4.3 Data wrangling",
    "text": "4.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph\nbuild network graph visualization using appropriate functions of ggraph\ncompute network geometrics using tidygraph\nbuild advanced graph visualization by incorporating the network geometrics\nbuild interactive network visualization using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "2.1 Installing and launching R packages",
    "text": "2.1 Installing and launching R packages\nWe will be using 4 network data modelling and visualization packages. They are igraph, tidygpraph, ggraph and visNetwork. Beside these four packages, tidyverse and libridate used for wrangling time data would also be used.\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "2.2 The Data",
    "text": "2.2 The Data\nGAStech_email_edge.csv, GAStech_email_edge-v2.csv and GAStech_email_node.csv would be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-data",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "2.3 Importing the data",
    "text": "2.3 Importing the data\nGAStech_email_edge-v2.csv and GAStech_email_node.csv would be imported in this step using read_csv\nCode chunk:\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#reviewing-the-imported-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#reviewing-the-imported-data",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "3.1 Reviewing the imported data",
    "text": "3.1 Reviewing the imported data\nUsing glimpse() we coud quickly examine the data\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nOutput of GAStech_edges shown that SentDate is treated as “Character” instead of date data. This is an error and need to be fixed before we continue"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#wrangling-time",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#wrangling-time",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "3.2 Wrangling time",
    "text": "3.2 Wrangling time\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SentDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 9,063\nColumns: 9\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ Weekday     &lt;ord&gt; Monday, Monday, Monday, Monday, Monday, Monday, Monday, Mo…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#wrangling-attributes",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#wrangling-attributes",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "3.3 Wrangling attributes",
    "text": "3.3 Wrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 1,456\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7,…\n$ Weekday &lt;ord&gt; Monday, Tuesday, Wednesday, Friday, Monday, Tuesday, Wednesday…\n$ Weight  &lt;int&gt; 4, 3, 5, 8, 4, 3, 5, 8, 4, 3, 5, 8, 4, 3, 5, 8, 4, 3, 5, 8, 4,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-tbl_graph-object",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-tbl_graph-object",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "4.1 The tbl_graph object",
    "text": "4.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-dplyr-verbs-in-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-dplyr-verbs-in-tidygraph",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "4.2 The dplyr verbs in tidygraph",
    "text": "4.2 The dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#using-tbl_graph-to-build-tidygraph-data-model",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#using-tbl_graph-to-build-tidygraph-data-model",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "4.3 Using tbl_graph() to build tidygraph data model",
    "text": "4.3 Using tbl_graph() to build tidygraph data model\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\nCode chunk:\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\nReviewing the output tidygraph’s graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1456 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,456 × 4\n   from    to Weekday   Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n1     1     2 Monday         4\n2     1     2 Tuesday        3\n3     1     2 Wednesday      5\n# ℹ 1,453 more rows\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#changing-the-active-object",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#changing-the-active-object",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "4.4 Changing the active object",
    "text": "4.4 Changing the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\nCode chunk\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1456 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,456 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Tuesday       23\n 2    40    43 Tuesday       19\n 3    41    43 Tuesday       15\n 4    41    40 Tuesday       14\n 5    42    41 Tuesday       13\n 6    42    40 Tuesday       12\n 7    42    43 Tuesday       11\n 8    43    42 Wednesday     11\n 9    36    32 Wednesday      9\n10    40    41 Monday         9\n# ℹ 1,446 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package-1",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package-1",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "5.1 Plotting Static Network Graphs with ggraph package",
    "text": "5.1 Plotting Static Network Graphs with ggraph package\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nset.seed(1234)\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#changing-the-default-network-graph-theme",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#changing-the-default-network-graph-theme",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "5.2 Changing the default network graph theme",
    "text": "5.2 Changing the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#changing-the-coloring-of-the-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#changing-the-coloring-of-the-plot",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "5.3 Changing the coloring of the plot",
    "text": "5.3 Changing the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\nCode chunk\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-ggraphs-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-ggraphs-layouts",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "5.4 Working with ggraph’s layouts",
    "text": "5.4 Working with ggraph’s layouts\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#fruchterman-and-reingold-layout",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#fruchterman-and-reingold-layout",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "5.5 Fruchterman and Reingold layout",
    "text": "5.5 Fruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\nset.seed(1234)\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#modifying-network-nodes",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#modifying-network-nodes",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "5.6 Modifying network nodes",
    "text": "5.6 Modifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#modifying-edges",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#modifying-edges",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "5.7 Modifying edges",
    "text": "5.7 Modifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\nset.seed(1234)\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width = Weight), \n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-facet_edges",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-facet_edges",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "6.1 Working with facet_edges()",
    "text": "6.1 Working with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width = Weight), \n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#changing-the-position-of-the-legend",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#changing-the-position-of-the-legend",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "6.2 Changing the position of the legend",
    "text": "6.2 Changing the position of the legend\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width = Weight), \n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#a-framed-facet-graph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#a-framed-facet-graph",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "6.3 A framed facet graph",
    "text": "6.3 A framed facet graph\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight),\n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-facet_nodes",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-facet_nodes",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "6.4 Working with facet_nodes()",
    "text": "6.4 Working with facet_nodes()\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width = Weight), \n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-centrality-indices",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-centrality-indices",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "7.1 Computing centrality indices",
    "text": "7.1 Computing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width = Weight),\n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n                      size = betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n##Things to learn from the code chunk above:\nmutate() of dplyr is used to perform the computation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-network-metrics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-network-metrics",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "7.2 Visualising network metrics",
    "text": "7.2 Visualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot. the algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width = Weight), \n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualizing-community",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualizing-community",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "7.3 Visualizing community",
    "text": "7.3 Visualizing community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "8.1 Data preparation",
    "text": "8.1 Data preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-the-first-interactive-network-graph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-the-first-interactive-network-graph",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "8.2 Plotting the first interactive network graph",
    "text": "8.2 Plotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-layout",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-layout",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "8.3 Working with layout",
    "text": "8.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-visual-attributes---nodes",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-visual-attributes---nodes",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "8.4 Working with visual attributes - Nodes",
    "text": "8.4 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department)\n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-visual-attributes---edges",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#working-with-visual-attributes---edges",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "8.5 Working with visual attributes - Edges",
    "text": "8.5 Working with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges. - The argument arrows is used to define where to place the arrow. - The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#interactivity",
    "title": "Hands-on Exercise 6 Modelling, Visualising and Analysing Network Data with R",
    "section": "8.6 Interactivity",
    "text": "8.6 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html",
    "href": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html",
    "title": "Hands-on Exercise 4.3 Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages.\n\n\n\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n            mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 4.3 Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "In this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#importing-the-data",
    "title": "Hands-on Exercise 4.3 Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "In this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n            mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#funnelplotr-methods-the-basic-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#funnelplotr-methods-the-basic-plot",
    "title": "Hands-on Exercise 4.3 Funnel Plots for Fair Comparisons",
    "section": "2.1 FunnelPlotR methods: The basic plot",
    "text": "2.1 FunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(covid19, numerator = Positive, denominator = Death,\n            group = `Sub-district`)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_type argument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#funnelplotr-methods-makeover-1",
    "href": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#funnelplotr-methods-makeover-1",
    "title": "Hands-on Exercise 4.3 Funnel Plots for Fair Comparisons",
    "section": "2.2 FunnelPlotR methods: Makeover 1",
    "text": "2.2 FunnelPlotR methods: Makeover 1\n\nfunnel_plot(covid19, \n            numerator = Death, denominator = Positive, group = `Sub-district`,\n            data_type = \"PR\", xrange = c(0, 6500), yrange = c(0, 0.05))\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#funnelplotr-methods-makeover-2",
    "href": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#funnelplotr-methods-makeover-2",
    "title": "Hands-on Exercise 4.3 Funnel Plots for Fair Comparisons",
    "section": "2.3 FunnelPlotR methods: Makeover 2",
    "text": "2.3 FunnelPlotR methods: Makeover 2\n\nfunnel_plot(covid19, \n            numerator = Death, denominator = Positive, group = `Sub-district`,\n            data_type = \"PR\", xrange = c(0, 6500), yrange = c(0, 0.05), label = NA,\n            title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\",\n            x_label = \"Cumulative COVID-19 Positive Cases\",\n            y_label = \"Cumulative Fatality Rate\")\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04.3/Hands-on_Ex04.3.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4.3 Funnel Plots for Fair Comparisons",
    "section": "2.4 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "2.4 Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, we will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n2.4.1 Computing the basic derived fields\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n2.4.2 Calculate lower and upper limits for 95% and 99.9% CI\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\n\ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n2.4.3 Plotting a static funnel plot\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), alpha=0.4) +\n  geom_line(data = dfCI, aes(x = number.seq, y = number.ll95), \n            size = 0.4, colour = \"grey40\", linetype = \"dashed\") +\n  geom_line(data = dfCI, aes(x = number.seq, y = number.ul95),\n            size = 0.4, colour = \"grey40\", linetype = \"dashed\") +\n  geom_line(data = dfCI, aes(x = number.seq, y = number.ll999), \n            size = 0.4, colour = \"grey40\") +\n  geom_line(data = dfCI, aes(x = number.seq, y = number.ul999), \n            size = 0.4, colour = \"grey40\") +\n  geom_hline(data = dfCI, aes(yintercept = fit.mean), \n             size = 0.4, colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12), legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7), legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n2.4.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p, tooltip = c(\"label\", \"x\", \"y\"))\n\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n\nThe Code chunk below uses p_load() function of pacman package to check if tidyverse and ggstatsplot packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(ggstatsplot, tidyverse) \n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\nhead(exam)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16\n\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(data = exam, x = ENGLISH, type = \"bayes\", \n             test.value = 60, xlab = \"English scores\")\n\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(data = exam, x = GENDER, y = MATHS, \n               type = \"np\", messages = FALSE)\n\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race\n\nggbetweenstats(data = exam, x = RACE, y = ENGLISH, type = \"parametric\",\n               mean.ci = TRUE, pairwise.comparisons = TRUE,\n               pairwise.display = \"s\", p.adjust.method = \"fdr\",\n               message = FALSE)\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(data = exam, x = MATHS, y = ENGLISH, marginal = FALSE)\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;%\n          mutate(MATHS_bins = cut(MATHS, breaks = c(0,60,75,85,100)))\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(data = exam1, x = MATHS_bins, y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#getting-started",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n\nThe Code chunk below uses p_load() function of pacman package to check if tidyverse and ggstatsplot packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(ggstatsplot, tidyverse) \n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\nhead(exam)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#one-sample-test-gghistostats-method",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#one-sample-test-gghistostats-method",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "",
    "text": "In the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(data = exam, x = ENGLISH, type = \"bayes\", \n             test.value = 60, xlab = \"English scores\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#two-sample-mean-test-ggbetweenstats",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#two-sample-mean-test-ggbetweenstats",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "",
    "text": "In the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(data = exam, x = GENDER, y = MATHS, \n               type = \"np\", messages = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#oneway-anova-test-ggbetweenstats-method",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#oneway-anova-test-ggbetweenstats-method",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "",
    "text": "In the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race\n\nggbetweenstats(data = exam, x = RACE, y = ENGLISH, type = \"parametric\",\n               mean.ci = TRUE, pairwise.comparisons = TRUE,\n               pairwise.display = \"s\", p.adjust.method = \"fdr\",\n               message = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#significant-test-of-correlation-ggscatterstats",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#significant-test-of-correlation-ggscatterstats",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "",
    "text": "In the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(data = exam, x = MATHS, y = ENGLISH, marginal = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#significant-test-of-association-depedence-ggbarstats-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#significant-test-of-association-depedence-ggbarstats-methods",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "",
    "text": "In the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;%\n          mutate(MATHS_bins = cut(MATHS, breaks = c(0,60,75,85,100)))\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(data = exam1, x = MATHS_bins, y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#getting-stated",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#getting-stated",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "2.0 Getting Stated",
    "text": "2.0 Getting Stated\n\n2.0.1 Installing and launching R packages\nThe Code chunk below uses p_load() function of pacman package to load the needed libaries.\n\npacman::p_load(readxl, performance, parameters, see)\n\npackage 'modelbased' successfully unpacked and MD5 sums checked\npackage 'see' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\tien_\\AppData\\Local\\Temp\\RtmpKKeTxk\\downloaded_packages\n\n\n\n\n2.0.2 Importing Excel file using readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nThe output object car_resale is a tibble data frame"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#multiple-regression-model-using-lm",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#multiple-regression-model-using-lm",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "2.1 Multiple Regression model using lm()",
    "text": "2.1 Multiple Regression model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(formula = Price ~ Age_08_04 + Mfg_Year + KM \n            + Weight + Guarantee_Period, data = car_resale)\n\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#model-diagnostic-checking-for-multicolinearity",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#model-diagnostic-checking-for-multicolinearity",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "2.2 Model Diagnostic: checking for multicolinearity:",
    "text": "2.2 Model Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#model-diagnostic-checking-normality-assumption",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#model-diagnostic-checking-normality-assumption",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "2.3 Model Diagnostic: checking normality assumption",
    "text": "2.3 Model Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period, \n             data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#model-diagnostic-check-model-for-homogeneity-of-variances",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#model-diagnostic-check-model-for-homogeneity-of-variances",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "2.4 Model Diagnostic: Check model for homogeneity of variances",
    "text": "2.4 Model Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#model-diagnostic-complete-check",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#model-diagnostic-complete-check",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "2.5 Model Diagnostic: Complete check",
    "text": "2.5 Model Diagnostic: Complete check\n\ncheck_model(model1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#visualising-regression-parameters-see-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#visualising-regression-parameters-see-methods",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "2.6 Visualising Regression Parameters: see methods",
    "text": "2.6 Visualising Regression Parameters: see methods\nIn the code chunk below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#visualising-regression-parameters-ggcoefstats-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04.1/Hands-on_Ex04.1.html#visualising-regression-parameters-ggcoefstats-methods",
    "title": "Hands-on Exercise 4.1 Visual Statistical Analysis",
    "section": "2.7 Visualising Regression Parameters: ggcoefstats() methods",
    "text": "2.7 Visualising Regression Parameters: ggcoefstats() methods\nIn the code chunk below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, I will be exploring interactive data visualisation by using functions provided by ggiraph and plotlyr packages\n\n\nThe Code chunk below uses p_load() function of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "The Code chunk below uses p_load() function of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#importing-the-data",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#tooltip-effect-with-tooltip-aesthetic",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#tooltip-effect-with-tooltip-aesthetic",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "2.1 Tooltip effect with tooltip aesthetic",
    "text": "2.1 Tooltip effect with tooltip aesthetic\n\nThe Code\n\np1 &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n      geom_dotplot_interactive(aes(tooltip = ID), stackgroups = TRUE, \n                               binwidth = 1, method = \"histodot\") +\n      scale_y_continuous(NULL,  breaks = NULL)\n\ngirafe(ggobj = p1, width_svg = 6,height_svg = 6*0.618)\n\nTwo steps are involved, first, an interactive version of ggplot2 geom (geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n###Interactivity\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#displaying-multiple-information-on-tooltip",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#displaying-multiple-information-on-tooltip",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "2.2 Displaying multiple information on tooltip",
    "text": "2.2 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nThe Code\n\nexam_data$tooltip &lt;- c(paste0( \"Name = \", exam_data$ID, \n                               \"\\n Class = \", exam_data$CLASS)) \n\np2 &lt;- ggplot(data=exam_data, aes(x = ENGLISH)) +\n      geom_dotplot_interactive(aes(tooltip = exam_data$tooltip), stackgroups = TRUE, \n                               binwidth = 1, method = \"histodot\") +\n      scale_y_continuous(NULL,  breaks = NULL)\n\ngirafe(ggobj = p2, width_svg = 8,height_svg = 8*0.618)\n\n###Interactivity\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#customising-tooltip-style",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#customising-tooltip-style",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "2.3 Customising Tooltip style",
    "text": "2.3 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations\n\nThe Code\n\ntooltip_css &lt;- \"background-color:white; font-style:bold; color:black;\"\n\np3 &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = ID), stackgroups = TRUE,\n                           binwidth = 1, method = \"histodot\") +               \n  scale_y_continuous(NULL,breaks = NULL)\n\ngirafe(ggobj = p3, width_svg = 6, height_svg = 6*0.618, \n       options = list(opts_tooltip(css = tooltip_css)))\n\n\n\nInteractivity\nThe background colour of the tooltip is black and the font colour is white and bold."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "3.1 Creating an interactive scatter plot: plot_ly() method",
    "text": "3.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, x = ~MATHS, y = ~ENGLISH)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#working-with-visual-variable-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#working-with-visual-variable-plot_ly-method",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "3.2 Working with visual variable: plot_ly() method",
    "text": "3.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nThe plotThe Code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, x = ~MATHS, y = ~ENGLISH, color = ~RACE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "3.3 Creating an interactive scatter plot: ggplotly() method",
    "text": "3.3 Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\np8 &lt;- ggplot(data=exam_data, aes(x = MATHS, y = ENGLISH)) +\n      geom_point(size=1) +\n      coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\nggplotly(p8)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#coordinated-multiple-views-with-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#coordinated-multiple-views-with-plotly",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "3.4 Coordinated Multiple Views with plotly",
    "text": "3.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\n2 scatterplots will be created by using ggplot2 functions.\nsubplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np9 &lt;- ggplot(data=d, aes(x = MATHS, y = ENGLISH)) +\n        geom_point(size=1) +\n        coord_cartesian(xlim=c(0,100),ylim=c(0,100))\n\np10 &lt;- ggplot(data=d, aes(x = MATHS, y = SCIENCE)) +\n        geom_point(size=1) +\n        coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\nsubplot(ggplotly(p9),\n        ggplotly(p10))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#interactive-data-table-dt-package",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#interactive-data-table-dt-package",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "4.1 Interactive Data Table: DT package",
    "text": "4.1 Interactive Data Table: DT package\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\nDT::datatable(exam_data, class= \"display\", style = \"bootstrap5\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#linked-brushing-crosstalk-method",
    "href": "Hands-on_Ex/Hands-on_Ex03.1/Hands-on_Ex03.1.html#linked-brushing-crosstalk-method",
    "title": "Hands-on Exercise 3.1 Programming Interactive Data Visualisation with R",
    "section": "4.2 Linked brushing: crosstalk method",
    "text": "4.2 Linked brushing: crosstalk method\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np11 &lt;- ggplot(d, aes(ENGLISH, MATHS)) + \n        geom_point(size=1) +\n        coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p11),\"plotly_selected\")  \n\ncrosstalk::bscols(gg, DT::datatable(d,class= \"display\", \n                                    style = \"bootstrap5\"), widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "The Code chunk below uses p_load() function of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "The Code chunk below uses p_load() function of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.1 Modifying a geometric object by changing aes()",
    "text": "5.1 Modifying a geometric object by changing aes()\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.2 Modifying a geometric object by changing geom()",
    "text": "5.2 Modifying a geometric object by changing geom()\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#using-geom-density-to-plots-kernel-density-estimate",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#using-geom-density-to-plots-kernel-density-estimate",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.3 Using geom-density() to plots kernel density estimate",
    "text": "5.3 Using geom-density() to plots kernel density estimate\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-box-plot-using-notched-plot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-box-plot-using-notched-plot",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "6.1 Plotting a simple box plot using notched plot",
    "text": "6.1 Plotting a simple box plot using notched plot\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#combining-box-plot-and-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#combining-box-plot-and-scatterplot",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "8.1 Combining box plot and scatterplot",
    "text": "8.1 Combining box plot and scatterplot\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             linewidth = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "9.1 Working with stat - the stat_summary() method",
    "text": "9.1 Working with stat - the stat_summary() method\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun=\"mean\",         \n               colour =\"red\",        \n               size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "9.2 Working with stat - the geom() method",
    "text": "9.2 Working with stat - the geom() method\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun =\"mean\",           \n             colour =\"red\",          \n             size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "9.3 Adding a best fit curve on a scatterplot",
    "text": "9.3 Adding a best fit curve on a scatterplot\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n\n\n\n\n9.3.1 Default smoothing method\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "10.1 Working with facet_wrap()",
    "text": "10.1 Working with facet_wrap()\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_grid-function",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_grid-function",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "10.2 facet_grid() function",
    "text": "10.2 facet_grid() function\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-coordinate",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-coordinate",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "11.1 Working with Coordinate",
    "text": "11.1 Working with Coordinate\n\n11.1.1 Flips the horizontal bar chart into vertical bar chart by using coord_flip()\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "11.2 Changing the y- and x-axis range",
    "text": "11.2 Changing the y- and x-axis range\n\n11.2.1 Fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-theme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-theme",
    "title": "Hands-on Exercise 1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "12.1 Working with theme",
    "text": "12.1 Working with theme\n\n12.1.1 Plot a horizontal bar chart using theme_gray()\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n12.1.2 Plotted using theme_classic()\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n12.1.3 Plotted using theme_minimal()\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_bw()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\nThis website is for showcasing works related to ISSS608 Visual Analytics and Application for homework and exercises."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "pacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-without-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-without-ggrepel",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "3.1 Working without ggrepel",
    "text": "3.1 Working without ggrepel\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, linewidth = 0.5) +\n  geom_label(aes(label = ID, colour = factor(RACE)), \n             hjust = 0.5, vjust = -0.5) +\n  coord_cartesian(xlim = c(0,100), ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "3.2 Working with ggrepel",
    "text": "3.2 Working with ggrepel\n\n3.2.1 Using geom_label_repel()\nSimply replace geom_label() by geom_label_repel()\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, linewidth = 0.5) +\n  geom_label_repel(aes(label = ID, colour = factor(RACE)),\n                   max.overlaps = 20, fontface = \"bold\") +\n  coord_cartesian(xlim = c(0,100), ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n3.2.1 Using geom_text_repel()\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x = MATHS, y = SCIENCE)) +\n  geom_point() +\n  geom_smooth(method = lm, linewidth = 0.5) +\n  geom_text_repel(aes(label = ID, colour = factor(RACE)),\n                   max.overlaps = 20, fontface = \"bold\") +\n  coord_cartesian(xlim = c(0,100), ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "4.1 Working with ggtheme package",
    "text": "4.1 Working with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\n4.1.1 The economist theme\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x= MATHS))+\n  geom_histogram(bins = 20, boundary = 100, color = \"grey10\", fill = \"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n4.1.2 The WSJ theme\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x= ENGLISH))+\n  geom_histogram(bins = 20, boundary = 100, color = \"grey10\", fill = \"grey90\") +\n  ggtitle(\"Distribution of English scores\") +\n  theme_wsj(base_size = 8)\n\n\n\n\n\n\n4.1.3 The fivethirtyeight theme\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x= SCIENCE))+\n  geom_histogram(bins = 20, boundary = 100, color = \"grey10\", fill = \"grey90\") +\n  ggtitle(\"Distribution of Science scores\") +\n  theme_fivethirtyeight()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthems-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthems-package",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "4.2 Working with hrbthems package",
    "text": "4.2 Working with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey10\", fill = \"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nUsing the elements of hrbrthemes\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey10\", fill = \"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18, base_size = 15, grid = \"Y\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-patchwork-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-patchwork-methods",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "5.1 Creating Composite Graphics: patchwork methods",
    "text": "5.1 Creating Composite Graphics: patchwork methods\nPatchwork package has a very simple syntax where we can create layouts:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "5.2 Combining two ggplot2 graphs",
    "text": "5.2 Combining two ggplot2 graphs\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np1 + p2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "5.3 Combining three ggplot2 graphs",
    "text": "5.3 Combining three ggplot2 graphs\n\n“|” operator to stack two ggplot2 graphs,\n“/” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p4) &\n  theme(plot.title = element_text(size = 8))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "5.4 Creating a composite figure with tag",
    "text": "5.4 Creating a composite figure with tag\nUse patchwork for auto-tagging capabilities\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p4) +\n  plot_annotation(tag_levels = '1') &\n  theme(plot.title = element_text(size = 8))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-figure-with-insert",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-figure-with-insert",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "5.5 Creating figure with insert",
    "text": "5.5 Creating figure with insert\nWith inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np4 + inset_element(p2, left = 0.02, right = 0.5, top = 1, bottom = 0.7)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "title": "Hands-on Exercise 2 Beyond ggplot2 Fundamentals",
    "section": "5.6 Creating a composite figure by using patchwork and ggtheme",
    "text": "5.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p4\npatchwork & theme_economist() & \n  theme(plot.title = element_text(size = 8))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html",
    "title": "Hands-on Exercise 3.2 Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "The Code chunk below uses p_load() function of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\", sheet=\"Data\") %&gt;%\n              mutate_at(col, as.factor) %&gt;%\n              mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\", sheet=\"Data\") %&gt;%\n              mutate(across(col, as.factor)) %&gt;%\n              mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 3.2 Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "The Code chunk below uses p_load() function of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#importing-the-data",
    "title": "Hands-on Exercise 3.2 Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "nfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\", sheet=\"Data\") %&gt;%\n              mutate_at(col, as.factor) %&gt;%\n              mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\", sheet=\"Data\") %&gt;%\n              mutate(across(col, as.factor)) %&gt;%\n              mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#building-a-static-population-bubble-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#building-a-static-population-bubble-plot",
    "title": "Hands-on Exercise 3.2 Programming Animated Statistical Graphics with R",
    "section": "2.1 Building a static population bubble plot",
    "text": "2.1 Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, size = Population, colour = Country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', x = '% Aged', y = '% Young')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#building-the-animated-bubble-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#building-the-animated-bubble-plot",
    "title": "Hands-on Exercise 3.2 Programming Animated Statistical Graphics with R",
    "section": "2.2 Building the animated bubble plot",
    "text": "2.2 Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, size = Population, colour = Country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', x = '% Aged', y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#building-an-animated-bubble-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#building-an-animated-bubble-plot-ggplotly-method",
    "title": "Hands-on Exercise 3.2 Programming Animated Statistical Graphics with R",
    "section": "3.1 Building an animated bubble plot: ggplotly() method",
    "text": "3.1 Building an animated bubble plot: ggplotly() method\nIn this sub-section, we will create an animated bubble plot by using ggplotly() method.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, aes(x = Old, y = Young, \n                            size = Population, colour = Country, frame = Year)) +\n      geom_point(aes(size = Population, frame = Year), \n                 alpha = 0.7, show.legend = FALSE) +\n      scale_colour_manual(values = country_colors) +\n      scale_size(range = c(2, 12)) +\n      labs(x = '% Aged', y = '% Young')\n\nggplotly(gg)\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, aes(x = Old, y = Young, \n                            size = Population, colour = Country, frame = Year)) +\n      geom_point(aes(size = Population), \n                 alpha = 0.7, show.legend = FALSE) +\n      scale_colour_manual(values = country_colors) +\n      scale_size(range = c(2, 12)) +\n      labs(x = '% Aged', y = '% Young') +\n      theme(legend.position='none')\n\nggplotly(gg)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#building-an-animated-bubble-plot-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03.2/Hands-on_Ex03.2.html#building-an-animated-bubble-plot-plot_ly-method",
    "title": "Hands-on Exercise 3.2 Programming Animated Statistical Graphics with R",
    "section": "3.2 Building an animated bubble plot: plot_ly() method",
    "text": "3.2 Building an animated bubble plot: plot_ly() method\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, y = ~Young, size = ~Population, color = ~Continent,\n          sizes = c(2, 100), frame = ~Year, text = ~Country, \n          hoverinfo = \"text\", type = 'scatter', mode = 'markers') %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package.\n\n\n\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering)\nggdist for visualising distribution and uncertainty.\n\n\n\n\n\n\n\nInstall package\n\n\n\nthe code below is used to install ungeviz from github\ndevtools::install_github(“wilkelab/ungeviz”)\n\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering)\nggdist for visualising distribution and uncertainty.\n\n\n\n\n\n\n\nInstall package\n\n\n\nthe code below is used to install ungeviz from github\ndevtools::install_github(“wilkelab/ungeviz”)\n\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#importing-the-data",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "",
    "text": "exam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-table",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-table",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "The table",
    "text": "The table\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-code",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-code",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "The code",
    "text": "The code\n\nknitr::kable(head(my_sum), format = 'html')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#plotting-standard-error-bars-of-point-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#plotting-standard-error-bars-of-point-estimates",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "2.1 Plotting standard error bars of point estimates",
    "text": "2.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-plot",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "The Plot",
    "text": "The Plot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-code-1",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-code-1",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "The Code",
    "text": "The Code\n\nggplot(data = my_sum) +\n  geom_errorbar(aes(x = RACE, ymin = mean - se, ymax = mean + se),\n                width = 0.2, color = \"black\", alpha = 0.9, size = 0.5) +\n  geom_point(aes(x= RACE, y = mean), \n             stat = \"identity\", color = \"red\", alpha = 1, size = 1.5) +\n  ggtitle(\"Standard error of mean MATHS score by RACE\")\n\n\n\n\n\n\n\nThings about the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#plotting-confidence-interval-of-point-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#plotting-confidence-interval-of-point-estimates",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "2.2 Plotting confidence interval of point estimates",
    "text": "2.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-plot-1",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-plot-1",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "The Plot",
    "text": "The Plot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-code-2",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-code-2",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "The Code",
    "text": "The Code\n\nggplot(data = my_sum) +\n  geom_errorbar(aes(x = reorder(RACE, -mean), \n                    ymin = mean-1.96*se, ymax = mean+1.96*se),\n                width = 0.2, color = \"black\", alpha = 0.9, size = 0.5) +\n  geom_point(aes(x = RACE, y = mean),\n             stat = \"identity\", color = \"red\", alpha = 1, size = 1.5) +\n  labs(x = \"MATHS score\", \n       title = \"95% confidence interval of mean MATHS score by RACE\")\n\n\n\n\n\n\n\nThings about the code chunk above\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "2.3 Visualizing the uncertainty of point estimates with interactive error bars",
    "text": "2.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, we will explore how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-plot-2",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-plot-2",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "The Plot",
    "text": "The Plot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-code-3",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#the-code-3",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "The Code",
    "text": "The Code\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n        geom_errorbar(aes(x=reorder(RACE, -mean), ymin=mean-2.58*se, \n                          ymax=mean+2.58*se), \n                     width=0.2, colour=\"black\", alpha=0.9, linewidth=0.5) +\n        geom_point(aes(x=RACE, y=mean, \n                     text = paste(\"Race:\", `RACE`, \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", color=\"red\",alpha=1, size = 1.5,) + \n        xlab(\"Race\") + \n        ylab(\"Average Scores\") + \n        theme_minimal() + \n        theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)) +\n        ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n        DT::datatable(shared_df, rownames = FALSE, class=\"compact\", width=\"100%\", \n                     options = list(pageLength = 10, scrollX=T), \n                     colnames = c(\"No. of pupils\", \"Avg Scores\", \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n            formatRound(columns=c('mean', 'sd', 'se'), digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "3.1 Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "3.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval() +\n  labs(title = \"Visualising confidence intervals of mean MATHS score\",\n       subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nIN the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95, point_interval = \"median_qi\") +\n  labs(title = \"Visualising confidence intervals of mean MATHS score\",\n       subtitle = \"Median Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#changing-interval",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#changing-interval",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "3.2 Changing interval",
    "text": "3.2 Changing interval\nMakeover the plot on previous part by showing 95% and 99% confidence intervals.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = c(0.95, 0.99), point_interval = \"mean_qi\", \n                     show.legend = FALSE) +\n  labs(title = \"Visualising confidence intervals of mean MATHS score\",\n       subtitle = \"Mean Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#showing-gradient-using-stat_gradientinterval",
    "href": "Hands-on_Ex/Hands-on_Ex04.2/Hands-on_Ex04.2.html#showing-gradient-using-stat_gradientinterval",
    "title": "Hands-on Exercise 4.2 Visualising Uncertainty",
    "section": "3.3 Showing gradient using stat_gradientinterval()",
    "text": "3.3 Showing gradient using stat_gradientinterval()\nThe code chunk below is showing gradient using color fill and stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n    stat_gradientinterval(.width = c(0.95, 0.99), point_interval = \"mean_qi\",\n                          fill = \"skyblue\", fill_type = \"segments\",\n                          show.legend = TRUE) +\n    labs(title = \"Visualising confidence intervals of mean MATHS score\",\n        subtitle = \"Gradient + Multiple-interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "",
    "text": "In this exercise, we will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, you will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nIn this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph)\nDT\nlubridate and hms.\n\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, \n               textplot, lubridate, hms, tidyverse, tidygraph, \n               ggraph, igraph)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-a-folder-list",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-a-folder-list",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "3.1 Creating a folder list",
    "text": "3.1 Creating a folder list\n\nnews20 &lt;- \"data/20news/\"\n\n\nread_folder &lt;- function(infolder) {\n    tibble(file = dir(infolder, full.names = TRUE)) %&gt;%\n    mutate(text = map(file, read_lines)) %&gt;%\n    transmute(id = basename(file), text) %&gt;% \n    unnest(text)}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#reading-in-all-the-messages-from-the-20news-folder",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#reading-in-all-the-messages-from-the-20news-folder",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "Reading in all the messages from the 20news folder",
    "text": "Reading in all the messages from the 20news folder\n\nraw_text &lt;- tibble(folder = dir(news20, full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), id, text)\n\nwrite_rds(raw_text, \"data/rds/news20.rds\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nread_lines() of readr package is used to read up to n_max lines from a file.\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#removing-header-and-automated-email-signitures",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#removing-header-and-automated-email-signitures",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "6.1 Removing header and automated email signitures",
    "text": "6.1 Removing header and automated email signitures\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing field such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\ncumsum() of base R is used to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#removing-lines-with-nested-text-representing-quotes-from-other-users.",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#removing-lines-with-nested-text-representing-quotes-from-other-users.",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "6.2 Removing lines with nested text representing quotes from other users.",
    "text": "6.2 Removing lines with nested text representing quotes from other users.\nIn this code chunk below, regular expressions are used to remove with nested text representing quotes from other users\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \"^In article &lt;\"))\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-words-in-newsgroups",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-words-in-newsgroups",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "6.4 Visualising Words in newsgroups",
    "text": "6.4 Visualising Words in newsgroups\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\nset.seed(1234)\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\n\nDT::datatable(words_by_newsgroup, \n              filter = 'top', \n              options = list(pageLength = 10, \n                             autoWidth = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-words-in-newsgroups-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-words-in-newsgroups-1",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "6.5 Visualising Words in newsgroups",
    "text": "6.5 Visualising Words in newsgroups\nThe wordcloud below is plotted by using ggwordcloud package.\nThe code chunk used:\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\n  ggplot(aes(label = word,\n             size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-tf-idf-within-newsgroups",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-tf-idf-within-newsgroups",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.1 Computing tf-idf within newsgroups",
    "text": "7.1 Computing tf-idf within newsgroups\nThe code chunk below uses bind_tf_idf() of tidytext to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-tf-idf-as-interactive-table",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-tf-idf-as-interactive-table",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.2 Visualising tf-idf as interactive table",
    "text": "7.2 Visualising tf-idf as interactive table\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, target = 'row',\n              lineHeight='25%')\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfilter() argument is used to turn control the filter UI.\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\nformatStyle() is used to customise the output table. In this example, the arguments target and lineHeight are used to reduce the line height by 25%.\n\n\n\nTo learn more about customising DT’s table, visit this link."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-tf-idf-within-newsgroups",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-tf-idf-within-newsgroups",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.3 Visualising tf-idf within newsgroups",
    "text": "7.3 Visualising tf-idf within newsgroups\nFacet bar charts technique is used to visualise the tf-idf values of science related newsgroup.\nThe code chunk used to prepare the plot.\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#counting-and-correlating-pairs-of-words-with-the-widyr-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#counting-and-correlating-pairs-of-words-with-the-widyr-package",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.4 Counting and correlating pairs of words with the widyr package",
    "text": "7.4 Counting and correlating pairs of words with the widyr package\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup, \n               word, \n               n, \n               sort = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-as-a-network",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-as-a-network",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.5 Visualising correlation as a network",
    "text": "7.5 Visualising correlation as a network\nNow, we can visualise the relationship between newgroups in network graph as shown below.\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#bigram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#bigram",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.6 Bigram",
    "text": "7.6 Bigram\nIn this code chunk below, a bigram data frame is created by using unnest_tokens() of tidytext.\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\n\nbigrams\n\n# A tibble: 28,827 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,817 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#counting-bigrams",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#counting-bigrams",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.7 Counting bigrams",
    "text": "7.7 Counting bigrams\nThe code chunk is used to count and sort the bigram data frame ascendingly.\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\n\nbigrams_count\n\n# A tibble: 19,888 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,878 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#cleaning-bigram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#cleaning-bigram",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.8 Cleaning bigram",
    "text": "7.8 Cleaning bigram\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\nbigrams_filtered\n\n# A tibble: 4,607 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,597 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#counting-the-bigram-again",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#counting-the-bigram-again",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.9 Counting the bigram again",
    "text": "7.9 Counting the bigram again\n\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)\n\nbigram_counts\n\n# A tibble: 4,138 × 3\n   word1   word2     n\n   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;\n 1 1       2        12\n 2 1       3        12\n 3 static  void     10\n 4 time    pad      10\n 5 1       4         8\n 6 infield fly       7\n 7 mat     28        6\n 8 vv      vv        6\n 9 1       5         5\n10 cock    crow      5\n# ℹ 4,128 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#create-a-network-graph-from-bigram-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#create-a-network-graph-from-bigram-data-frame",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.10 Create a network graph from bigram data frame",
    "text": "7.10 Create a network graph from bigram data frame\nIn the code chunk below, a network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n                  filter(n &gt; 3) %&gt;%\n                  graph_from_data_frame()\n\n\nbigram_graph\n\nIGRAPH d20143b DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from d20143b (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualizing-a-network-of-bigrams-with-ggraph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualizing-a-network-of-bigrams-with-ggraph",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.11 Visualizing a network of bigrams with ggraph",
    "text": "7.11 Visualizing a network of bigrams with ggraph\nIn this code chunk below, ggraph package is used to plot the bigram.\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#revised-version",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#revised-version",
    "title": "Hands-on Exercise 5 Visualising and Analysing Text Data with R: tidytext methods",
    "section": "7.11 Revised version",
    "text": "7.11 Revised version\nThe code chunl used to re-plot the network graph.\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "2.1 Installing and launching R packages",
    "text": "2.1 Installing and launching R packages\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\npackage 'rootSolve' successfully unpacked and MD5 sums checked\npackage 'lmom' successfully unpacked and MD5 sums checked\npackage 'expm' successfully unpacked and MD5 sums checked\npackage 'Exact' successfully unpacked and MD5 sums checked\npackage 'gld' successfully unpacked and MD5 sums checked\npackage 'productplots' successfully unpacked and MD5 sums checked\npackage 'libcoin' successfully unpacked and MD5 sums checked\npackage 'Formula' successfully unpacked and MD5 sums checked\npackage 'inum' successfully unpacked and MD5 sums checked\npackage 'effectsize' successfully unpacked and MD5 sums checked\npackage 'DescTools' successfully unpacked and MD5 sums checked\npackage 'ggmosaic' successfully unpacked and MD5 sums checked\npackage 'partykit' successfully unpacked and MD5 sums checked\npackage 'sjstats' successfully unpacked and MD5 sums checked\npackage 'CGPfunctions' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\tien_\\AppData\\Local\\Temp\\Rtmpqql2MG\\downloaded_packages\npackage 'ggHoriPlot' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\tien_\\AppData\\Local\\Temp\\Rtmpqql2MG\\downloaded_packages"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "2.2 The Data",
    "text": "2.2 The Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#examining-the-data-structure",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#examining-the-data-structure",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "2.3. Examining the data structure",
    "text": "2.3. Examining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nkable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-preparation",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "2.4 Data Preparation",
    "text": "2.4 Data Preparation\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts,\n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-the-calendar-heatmaps",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-the-calendar-heatmaps",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "3.1 Building the Calendar Heatmaps",
    "text": "3.1 Building the Calendar Heatmaps\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "4.1 Data Import",
    "text": "4.1 Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#deriving-month-and-year-fields",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#deriving-month-and-year-fields",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "4.2 Deriving month and year fields",
    "text": "4.2 Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#extracting-the-target-country",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#extracting-the-target-country",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "4.3 Extracting the target country",
    "text": "4.3 Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#computing-year-average-arrivals-by-month",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#computing-year-average-arrivals-by-month",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "4.4 Computing year average arrivals by month",
    "text": "4.4 Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-cycle-plot",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "4.5 Plotting the cycle plot",
    "text": "4.5 Plotting the cycle plot\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import-1",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import-1",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "5.1 Data Import",
    "text": "5.1 Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-slopegraph",
    "title": "Hands-on Exercise 7 Visualising and Analysing Time-oriented Data",
    "section": "5.2 Plotting the slopegraph",
    "text": "5.2 Plotting the slopegraph\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html",
    "title": "Hands-on Exercise 8.2 Choropleth Mapping with R,",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, we can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, we will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\nBy the end of this hands-on exercise, we will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#the-data",
    "title": "Hands-on Exercise 8.2 Choropleth Mapping with R,",
    "section": "3.1 The data",
    "text": "3.1 The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#data-import-and-preparation",
    "title": "Hands-on Exercise 8.2 Choropleth Mapping with R,",
    "section": "3.2 Data Import and Preparation",
    "text": "3.2 Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 8.2 Choropleth Mapping with R,",
    "section": "3.3 Creating a sf data frame from an aspatial data frame",
    "text": "3.3 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\n\n\n\n\n\nTip\n\n\n\n##Things to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\n\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#it-all-started-with-an-interactive-point-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#it-all-started-with-an-interactive-point-symbol-map",
    "title": "Hands-on Exercise 8.2 Choropleth Mapping with R,",
    "section": "4.1 It all started with an interactive point symbol map",
    "text": "4.1 It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf) +\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#lets-make-it-proportional",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#lets-make-it-proportional",
    "title": "Hands-on Exercise 8.2 Choropleth Mapping with R,",
    "section": "4.2 Lets make it proportional",
    "text": "4.2 Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf) +\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#lets-give-it-a-different-colour",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#lets-give-it-a-different-colour",
    "title": "Hands-on Exercise 8.2 Choropleth Mapping with R,",
    "section": "4.3 Lets give it a different colour",
    "text": "4.3 Lets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf) +\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#working-with-faceted-plots",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#working-with-faceted-plots",
    "title": "Hands-on Exercise 8.2 Choropleth Mapping with R,",
    "section": "4.4 Working with faceted plots",
    "text": "4.4 Working with faceted plots\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman is used to load tidyverse family of packages.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman is used to load tidyverse family of packages.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-the-data",
    "title": "In-class Exercise 1",
    "section": "Importing the data",
    "text": "Importing the data\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")\n\n\nrealis.csv &lt;- read.csv(\"data/realis2019.csv\")\n\n\nggplot(data = realis,\n       aes(x = `Unit Price ($ psm)`)) +\n  geom_histogram()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#histogram",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#histogram",
    "title": "In-class Exercise 4",
    "section": "3.1 Histogram",
    "text": "3.1 Histogram\n\n3.1.1 Histogram with Parametric method\n\np &lt;- gghistostats(data = exam, \n             x = ENGLISH, \n             type = \"p\", \n             test.value = 60,\n             bin.args = list(color =\"black\", \n                             fill = \"lightblue\", \n                             alpha = 0.7),\n             normal.curve = FALSE, \n             normal.curve.args = list(linewidth = 2),\n             xlab = \"English Scores\")\np\n\n\n\n\n\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 15\n     mu statistic df.error  p.value method            alternative effectsize\n  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     \n1    60      8.77      321 1.04e-16 One Sample t-test two.sided   Hedges' g \n  estimate conf.level conf.low conf.high conf.method conf.distribution n.obs\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;int&gt;\n1    0.488       0.95    0.372     0.603 ncp         t                   322\n  expression\n  &lt;list&gt;    \n1 &lt;language&gt;\n\n$caption_data\n# A tibble: 1 × 16\n  term       effectsize      estimate conf.level conf.low conf.high    pd\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Difference Bayesian t-test     7.16       0.95     5.54      8.75     1\n  prior.distribution prior.location prior.scale    bf10 method         \n  &lt;chr&gt;                       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 cauchy                          0       0.707 4.54e13 Bayesian t-test\n  conf.method log_e_bf10 n.obs expression\n  &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt; &lt;list&gt;    \n1 ETI               31.4   322 &lt;language&gt;\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL\n\n\n\n\n3.1.2 Histogram with Non-parametric method\n\np1 &lt;- gghistostats(data = exam, \n             x = ENGLISH, \n             type = \"np\", \n             test.value = 60,\n             bin.args = list(color =\"black\", \n                             fill = \"lightblue\", \n                             alpha = 0.7),\n             normal.curve = FALSE, \n             normal.curve.args = list(linewidth = 2),\n             xlab = \"English Scores\")\np1\n\n\n\n\n\nextract_stats(p1)\n\n$subtitle_data\n# A tibble: 1 × 12\n  statistic  p.value method                    alternative effectsize       \n      &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;                     &lt;chr&gt;       &lt;chr&gt;            \n1     38743 3.43e-16 Wilcoxon signed rank test two.sided   r (rank biserial)\n  estimate conf.level conf.low conf.high conf.method n.obs expression\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt; &lt;list&gt;    \n1    0.528       0.95    0.430     0.613 normal        322 &lt;language&gt;\n\n$caption_data\nNULL\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL\n\n\n\n\n3.1.3 Histogram with Robust method\n\np2 &lt;- gghistostats(data = exam, \n             x = ENGLISH, \n             type = \"robust\", \n             test.value = 60,\n             bin.args = list(color =\"black\", \n                             fill = \"lightblue\", \n                             alpha = 0.7),\n             normal.curve = FALSE, \n             normal.curve.args = list(linewidth = 2),\n             xlab = \"English Scores\")\np2\n\n\n\n\n\n\n3.1.4 Histogram with Bayes method\n\np3 &lt;- gghistostats(data = exam, \n             x = ENGLISH, \n             type = \"bayes\", \n             test.value = 60,\n             bin.args = list(color =\"black\", \n                             fill = \"lightblue\", \n                             alpha = 0.7),\n             normal.curve = TRUE, \n             normal.curve.args = list(linewidth = 1, \n                                      color = \"red\"),\n             xlab = \"English Scores\")\np3"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#ggdotplotstats",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#ggdotplotstats",
    "title": "In-class Exercise 4",
    "section": "3.2 ggdotplotstats()",
    "text": "3.2 ggdotplotstats()\n\nggdotplotstats(data = exam,\n               x = ENGLISH,\n               y = CLASS,\n               title = \"\",\n               xlab = \"\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#ggwithinstats",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#ggwithinstats",
    "title": "In-class Exercise 4",
    "section": "3.3 ggwithinstats()",
    "text": "3.3 ggwithinstats()\n\nexam_new &lt;- exam %&gt;%\n            pivot_longer(cols = ENGLISH:SCIENCE,\n                         names_to = \"SUBJECT\",\n                         values_to = \"SCORES\")\n\nggwithinstats(data = filter(exam_new, \n                            SUBJECT %in% c(\"MATHS\", \"SCIENCE\"), \n                            CLASS %in% c(\"3A\")),\n              x = SUBJECT,\n              y = SCORES,\n              type = \"p\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#ggscatterstats",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#ggscatterstats",
    "title": "In-class Exercise 4",
    "section": "3.4 ggscatterstats()",
    "text": "3.4 ggscatterstats()\n\nggscatterstats(data = exam,\n               x = MATHS,\n               y = ENGLISH,\n               marginal = TRUE,\n               label.var = ID,\n               label.expression = ENGLISH &gt; 90 & MATHS &gt; 90)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#loading-and-processing-the-data",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#loading-and-processing-the-data",
    "title": "In-class Exercise 6",
    "section": "1.2. Loading and processing the data",
    "text": "1.2. Loading and processing the data\nThis below is based on https://kgjerde.github.io/corporaexplorer/articles/bible.html King James Bible exploration guide\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n\n\n# Collapsing into one string.\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\n\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\nMetadata\n\n# We are not quite happy with the long book titles in the King James Bible,\n  # so we retrieve shorter versions from esv.org which will take up less\n  # space in the corpus map plot.\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\nCreating data frame with text and metadata\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\ncorporaexplorer\n\n# As this is a corpus which is not organised by date,\n  # we set `date_based_corpus` to `FALSE`.\n# Because we want to organise our exploration around the books in the Bible,\n  # we pass `\"Book\"` to the `grouping_variable` argument.\n# We specify which metadata columns we want to be displayed in the\n  # \"Document information\" tab, using the `columns_doc_info` argument.\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\n\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#loading-packages",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#loading-packages",
    "title": "In-class Exercise 6",
    "section": "2.1 Loading packages",
    "text": "2.1 Loading packages\n\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts,\n               ggforce, skimr, tidytext, tidyverse)\n\n\nmc3_data &lt;- fromJSON(\"data/MC3.json\")\n\nEdge\n\nmc3_edges &lt;- as_tibble(mc3_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %&gt;%\n  group_by(source, target, type) %&gt;%\n  summarise(weights = n()) %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\n\n\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %&gt;%\n  select(id, country, type, revenue_omu, product_services)\n\n\ncreating mc3_nodes1\n\nid1 &lt;- mc3_edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\n\nid2 &lt;- mc3_edges %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\n\nmc3_nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\n\n\nGraph Model\n\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\n\nmc3_graph %&gt;%\n  filter(betweenness_centrality &gt;= 200000) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(size = betweenness_centrality,\n                      colors = \"lightblue\",\n                      alpha = 0.5)) +\n  scale_size_continuous(range = c(1, 10)) +\n  theme_graph()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find coursework prepared for this course."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "Assuming the role of a graphical editor of a median company, the purpose of this data visualization exercise is to prepare minimum two and maximum three data visualizations to reveal interesting insights on the private residential market and sub-markets of Singapore for the 1st quarter of 2024 and prior periods.\nTake-home Exercise 1\n\n\n\nFor this exercise and to accomplish the task, transaction data of REALIS will be used, which provides comprehensive and up-to-date statistics on the property market in Singapore.\nA complete set of the private residential property transaction data from 1st January 2023 to 31st March 2024"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-task",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "Assuming the role of a graphical editor of a median company, the purpose of this data visualization exercise is to prepare minimum two and maximum three data visualizations to reveal interesting insights on the private residential market and sub-markets of Singapore for the 1st quarter of 2024 and prior periods.\nTake-home Exercise 1"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "For this exercise and to accomplish the task, transaction data of REALIS will be used, which provides comprehensive and up-to-date statistics on the property market in Singapore.\nA complete set of the private residential property transaction data from 1st January 2023 to 31st March 2024"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-the-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-the-packages",
    "title": "Take-home Exercise 2",
    "section": "2.1 Loading the packages",
    "text": "2.1 Loading the packages\nFor this Take-home exercise 2, I am planning to use libraries that my classmate has put into their code below:\ntidyverse: The tidyverse is an opinionated collection of R packages designed for data science.\npatchwork: a package to make it simple to combine separate ggplots into the same graphic\nggrepel: a package to provide geoms for ggplot2 to repel overlapping text labels\nggthemes: a package to provide some extra themes, geoms, and scales for ‘ggplot2’.\nggridges: a package for Ridgeline plots, which are partially overlapping line plots that create the impression of a mountain range.\nggdist: an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualizing distributions and uncertainty which will assist with ggridges package\ncolorspace: provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualizations.\n\nThe Code:\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes,\n               tidyverse, ggridges, ggdist, colorspace)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-the-data",
    "title": "Take-home Exercise 2",
    "section": "2.2 Loading the data",
    "text": "2.2 Loading the data\nFor the take-home exercise purpose I will follow me classmate data steps:\n\nrealis_data_2023Q1 &lt;- read_csv(\"data/ResidentialTransaction20240308160536.csv\")\nrealis_data_2023Q1 &lt;- mutate(realis_data_2023Q1, Quarter='2023-Q1')\nrealis_data_2023Q2 &lt;- read_csv(\"data/ResidentialTransaction20240308160736.csv\")\nrealis_data_2023Q2 &lt;- mutate(realis_data_2023Q2, Quarter='2023-Q2')\nrealis_data_2023Q3 &lt;- read_csv(\"data/ResidentialTransaction20240308161009.csv\")\nrealis_data_2023Q3 &lt;- mutate(realis_data_2023Q3, Quarter='2023-Q3')\nrealis_data_2023Q4 &lt;- read_csv(\"data/ResidentialTransaction20240308161109.csv\")\nrealis_data_2023Q4 &lt;- mutate(realis_data_2023Q4, Quarter='2023-Q4')\nrealis_data_2024Q1 &lt;- read_csv(\"data/ResidentialTransaction20240414220633.csv\")\nrealis_data_2024Q1 &lt;- mutate(realis_data_2024Q1, Quarter='2024-Q1')\n\nrealis_data &lt;- rbind(realis_data_2023Q1, realis_data_2023Q2, realis_data_2023Q3, realis_data_2023Q4, realis_data_2024Q1)\nrealis_data$Month &lt;- substr(realis_data$`Sale Date`,3,6)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-original-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-original-design",
    "title": "Take-home Exercise 2",
    "section": "3.1 The original design",
    "text": "3.1 The original design\nThis original design was taken from my classmate submission Take-home Exercise 1\n\nggplot(realis_data, aes(x = Quarter, fill =`Type of Sale`)) + \n  geom_bar() +  \n  theme_minimal() + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  \n  facet_wrap(~`Property Type`,scales = \"free_y\") + \n  ggtitle(label = \"Number of properties sold for each type per quarter\") + ylab(\"Number of properties sold\") + xlab(\"Quarter\")\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nFrom the data visualizations above, here are my starting observations\n\nThis graph purpose seems to be to showcase the number of properties sold for each Type of Sale per Property Type per Quarter.\nThe Property Type is separated into 2 rows grids\nDifferent color theme representing different Type of Sale."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-of-the-original-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-of-the-original-design",
    "title": "Take-home Exercise 2",
    "section": "3.2 Critique of the original design",
    "text": "3.2 Critique of the original design\n\n\n\nFigure 1. Classmate plot\n\n\n\nPlot size: the plot size is a bit small.\nScale of measurement: since the different Property Type grid are put together this create an illusion that their scale should be the same. However, in actual fact, the plot scale is all over the place and create a misleading visualization of the actual sales for each Property Type. It would also be nice if we could have y axes on one side of the plot only to show that they are of the same scale\n2 rows grids: The Property Type separated into 2 rows grids in itself is not really a problem. However, for me personally, I think it would be nice if we could put them on the same row for easier comparison and also since there are only 6 Property Type, we could manipulate the plot to make it fit somehow\nThe label: Number of properties sold for each type per quarter is missing the Type of Sale part of the graph.\nGrid separation: it woule be nice if I could have a line or box to separate the grid so viewer could separate between which Property Type they are looking at\nThe legends: somehow the legend is taking a huge portion of the plot (approximately 1/4), this feels like such a waste of space and make it visually unattractive in a sense. It could be due to my classmate using the theme_minimal(), using a different theme and adjusting the legend position to make more space for the actual plot may make a big different here."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#make-over-of-the-original-design.",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#make-over-of-the-original-design.",
    "title": "Take-home Exercise 2",
    "section": "3.3 Make over of the original design.",
    "text": "3.3 Make over of the original design.\nWith the above 3 critiques made, I will go into details below on what I plan to do with the original design to address each point. Then, I will show the final code and the alternative design\n\nPlot size:\nI will be adjusting the size of the plot by putting some adjustment to the R code chunk using {r fig.height = 8, fig.width = 18} instead of {r}\n\n\nScale of measurement:\nThis is actually quite an easy fix, by using the Cartesian coordinates via coord_cartesian() we could adjust the limits for the y axes and preventing the plot. With the knowledge of the original plot that the limit of y fall somewhere between 0 and 2600, I could just add in coord_cartesian(ylim=c(0,2600))\n\n\n2 rows grids:\nThe original code for creating the multifaceted facet_wrap(~Property Type,scales = “free_y”). However, as mentioned, for comparison purpose, I prefer if they could be on the same row with the same scale. Therefore, I will be replacing the above line of code with facet_wrap(~Property Type, nrow = 1) instead\n\n\nThe label:\nI will be renaming the plot to Number of properties sold for each Type of Sale per Property Type per Quarter.\n\n\nGrid separation:\nAnother easy change we just need to adjust the panel using panel.border argument of the gglot2 theme() here. For this purpose, I will be using\ntheme(panel.border = element_rect(color = “grey10”, linetype = “solid”, linewidth = 1)\n\n\nThe legends\nSo for this part, there is a lot of things to make adjustment here since I will be using a different theme, theme_economist() to be specific. With this theme changes, I will be adjust a multitude of arguments of the of the gglot2 theme() to adjust both the text size as well as the margin between the text and the plot. These arguments include axis.text, axis.title, title, strip.text, axis.title.y, axis.title.x\n\n\nFinal Result\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\nggplot(realis_data, aes(x = Quarter, \n                        fill =`Type of Sale`)) +\n  geom_bar() +\n  \n  coord_cartesian(ylim=c(0,2600)) +\n  \n  facet_wrap(~`Property Type`, nrow = 1) +\n  \n  theme_economist() +\n  ggtitle(label = \"Number of properties sold for each Type of Sale per Property Type per Quarter\") +\n  ylab(\"Number of properties sold\") +\n  xlab(\"Quarter\") + \n  theme(axis.text=element_text(size = 9), \n        axis.title = element_text(size = 15), \n        title = element_text(size = 15, \n                               margin = margin(b = 15,)),\n        strip.text = element_text(margin = margin(b = 15)),\n        axis.title.y = element_text(margin = margin(r = 15)),\n        axis.title.x = element_text(margin = margin(t = 15)),\n        panel.border = element_rect(color = \"grey10\", \n                                    linetype = \"solid\", \n                                    linewidth = 1))\n\n\n\n\n\n\nClarity Improvements\n\nPlot size and font size and other margin are adjusted to mae sure no overlapping of texts\nConsistent scale of y-axis allows fair comparisons of properties sales and patterns across different Property Type, which is especially important since the sales for different Property Type differ greatly.\nThe title has been change to reflect correctly the visualization being made\nLegend is adjusted to the top, creating more space for the actual plot.\nFor readability sake, I have adjust the x-axes text to be horizontal instead of slanted like the original design"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-of-the-make-over-of-the-original-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-of-the-make-over-of-the-original-design",
    "title": "Take-home Exercise 2",
    "section": "3.4 Critique of the make over of the original design",
    "text": "3.4 Critique of the make over of the original design\nSo the resulting plot of the make over of the original design seems to address the critiques made originally. However, I think this design could be improve event further. One critique I want to make here is that since the scale is 0 to 2600, it maybe too big to show the “Sub Sale” and “New Sale” of some of the Property Type. In addition, since this is a stacked plot, it is a bit difficult if viewer want to see the changes of the different Type of Sale over time.\nTherefore, I thought to myself what if I could separate the Type of Sale as well and hence reduce the scale of count so the missing “Sub Sale” and “New Sale” could be shown as well."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-further-make-over",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-further-make-over",
    "title": "Take-home Exercise 2",
    "section": "3.5 The further make over",
    "text": "3.5 The further make over\nIt is actually quite simple to separate the Type of Sale. However, instead of using the facet_wrap(), I will switch to using facet_grid().\nSimply replacing facet_wrap(~Property Type, nrow = 1) with facet_grid(cols = vars(Property Type), rows = vars(Type of Sale)), and also removing fill =Type of Sale from ggplot since we will not really need the color to show different Type of Sale\n\nFinal Result\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\nggplot(realis_data, aes(x = Quarter)) + \n  geom_bar(fill = \"lightblue4\") +  \n  coord_cartesian(expand = TRUE, \n                  ylim = c(0,1680)) +\n\n  facet_grid(cols = vars(`Property Type`),\n             rows = vars(`Type of Sale`)) +\n  \n\n  theme_economist() +\n  ggtitle(label = \"Number of properties sold for each Type of Sale per Property Type per Quarter\") +    \n  ylab(\"Number of properties sold\") + \n  xlab(\"Quarter\") + \n  theme(axis.text=element_text(size = 9), \n        axis.title = element_text(size = 15), \n        title = element_text(size = 15,\n                             margin = margin(b = 15,)),\n        strip.text = element_text(margin = margin(b = 10,\n                                                  l = 10)),\n        strip.text.y.right = element_text(angle = 0),\n        axis.title.y = element_text(margin = margin(r = 15)),\n        axis.title.x = element_text(margin = margin(t = 15)),\n        panel.border = element_rect(color = \"grey10\", \n                                    linetype = \"solid\", \n                                    linewidth = 1))\n\n\n\n\nThe resulting plot seems to be doing better. However, some smaller count property type sale is still nowhere to be seen and is negligible."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "With reference to the Mini-Challenge 3 of VAST Challenge 2024.\nA key element in stopping illegal fishing is holding the people who own nefarious companies accountable. Thus, FishEye is keenly interested in developing visualization tools that work with CatchNet to identify the people who hold influence over business networks. That is especially difficult with varied and changing shareholder and ownership relationships. My main focus for this portion would be on:\nCreate a visual analytics approach that analysts can use to highlight temporal patterns and changes in corporate structures. Examine the most active people and businesses using visual analytics.\nBelow is a further clarification from organizer\n\n\n\n\n\n\n1. What level of corporate change is of interest?\n\n\n\nQuestion\nDoes the concept of ‘changes in corporate structures over time’ mean the changes in one corporation,like the changes of board of the company, or the changes happening in the whole society, like the ratio of some kind of companies?\nClarification\nFishEye is more interested in the ways in which the structures of individual corporations change over time, rather than macro-economic or industry-level changes in the Oceanus marketplace. In some cases the corporate structure of several organizations may be intertwined (such as when one company owns another) and the relationships between them would therefore be relevant. Systematic trends in the ways individual companies re-structure over time could also be interesting. However, any large-scale changes in the structure of the economy are not the intention.\n\n\nSo it looks like being to show the changes over time is important"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-data",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "The data used for this part would be the mc3.json file download from the VAST MC3 website"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-and-launching-of-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-and-launching-of-r-packages",
    "title": "Take-home Exercise 3",
    "section": "1. Loading and launching of R Packages",
    "text": "1. Loading and launching of R Packages\nBelow is a list of R Packages I am planning to use for this portion and for exploration\n\nplotly for creating interactive web-based graphs via the open source JavaScript.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\njsonlite JSON parser and generator optimized for statistical data and the web.\nigraph for creating and manipulating graphs and analyzing networks.\ntidygraph provides a tidy framework for all things relational (networks/graphs, trees, etc.)\nggraph an extension of the ggplot2 API tailored to graph visualizations and provides the same flexible approach to building up plots layer by layer.\nvisNetwork for network visualization.\nggforce collection of mainly new stats and geoms for composing specialised plots\nskimr provides summary statistics about variables in data frames, tibbles, data tables and vectors.\ntidyverse an opinionated collection of R packages designed for data science.\n\n\npacman::p_load(plotly, DT, jsonlite, igraph, \n               tidygraph, ggraph, visNetwork,\n               ggforce, skimr, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-the-data",
    "title": "Take-home Exercise 3",
    "section": "2. Importing the data",
    "text": "2. Importing the data\nI import the data from mc3.json file using the fromJSON() function\n\nmc3_data &lt;- fromJSON(\"data/mc3.json\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#quick-look-at-the-mc3-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#quick-look-at-the-mc3-data",
    "title": "Take-home Exercise 3",
    "section": "1. Quick look at the mc3 data",
    "text": "1. Quick look at the mc3 data\n\nglimpse(mc3_data)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 60520 obs. of  15 variables:\n  ..$ type             : chr [1:60520] \"Entity.Organization.Company\" \"Entity.Organization.Company\" \"Entity.Organization.Company\" \"Entity.Organization.Company\" ...\n  ..$ country          : chr [1:60520] \"Uziland\" \"Mawalara\" \"Uzifrica\" \"Islavaragon\" ...\n  ..$ ProductServices  : chr [1:60520] \"Unknown\" \"Furniture and home accessories\" \"Food products\" \"Unknown\" ...\n  ..$ PointOfContact   : chr [1:60520] \"Rebecca Lewis\" \"Michael Lopez\" \"Steven Robertson\" \"Anthony Wyatt\" ...\n  ..$ HeadOfOrg        : chr [1:60520] \"Émilie-Susan Benoit\" \"Honoré Lemoine\" \"Jules Labbé\" \"Dr. Víctor Hurtado\" ...\n  ..$ founding_date    : chr [1:60520] \"1954-04-24T00:00:00\" \"2009-06-12T00:00:00\" \"2029-12-15T00:00:00\" \"1972-02-16T00:00:00\" ...\n  ..$ revenue          : num [1:60520] 5995 71767 0 0 4747 ...\n  ..$ TradeDescription : chr [1:60520] \"Unknown\" \"Abbott-Gomez is a leading manufacturer and supplier of high-quality furniture and home accessories, catering to\"| __truncated__ \"Abbott-Harrison is a leading manufacturer of high-quality food products, including baked goods, snacks, and bev\"| __truncated__ \"Unknown\" ...\n  ..$ _last_edited_by  : chr [1:60520] \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" ...\n  ..$ _last_edited_date: chr [1:60520] \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _date_added      : chr [1:60520] \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _raw_source      : chr [1:60520] \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" ...\n  ..$ _algorithm       : chr [1:60520] \"Automatic Import\" \"Automatic Import\" \"Automatic Import\" \"Automatic Import\" ...\n  ..$ id               : chr [1:60520] \"Abbott, Mcbride and Edwards\" \"Abbott-Gomez\" \"Abbott-Harrison\" \"Abbott-Ibarra\" ...\n  ..$ dob              : chr [1:60520] NA NA NA NA ...\n $ links     :'data.frame': 75817 obs. of  11 variables:\n  ..$ start_date       : chr [1:75817] \"2016-10-29T00:00:00\" \"2035-06-03T00:00:00\" \"2028-11-20T00:00:00\" \"2024-09-04T00:00:00\" ...\n  ..$ type             : chr [1:75817] \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" ...\n  ..$ _last_edited_by  : chr [1:75817] \"Pelagia Alethea Mordoch\" \"Niklaus Oberon\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" ...\n  ..$ _last_edited_date: chr [1:75817] \"2035-01-01T00:00:00\" \"2035-07-15T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _date_added      : chr [1:75817] \"2035-01-01T00:00:00\" \"2035-07-15T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _raw_source      : chr [1:75817] \"Existing Corporate Structure Data\" \"Oceanus Corporations Monthly - Jun '35\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" ...\n  ..$ _algorithm       : chr [1:75817] \"Automatic Import\" \"Manual Entry\" \"Automatic Import\" \"Automatic Import\" ...\n  ..$ source           : chr [1:75817] \"Avery Inc\" \"Berger-Hayes\" \"Bowers Group\" \"Bowman-Howe\" ...\n  ..$ target           : chr [1:75817] \"Allen, Nichols and Thompson\" \"Jensen, Morris and Downs\" \"Barnett Inc\" \"Bennett Ltd\" ...\n  ..$ key              : int [1:75817] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ end_date         : chr [1:75817] NA NA NA NA ...\n\n\nThe main data in this mc3.json file includes 2 data frame nodes and links, hence I will further breakdown and review the data in these 2 data frames."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dataframe-nodes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dataframe-nodes",
    "title": "Take-home Exercise 3",
    "section": "2. Dataframe nodes",
    "text": "2. Dataframe nodes\nFirst I import this nodes data using as_tibble() function and have a quick glimpse() at the data itself, let call this data mc3_nodes_raw\nNodes\n\n\nShow the code\nmc3_nodes_raw &lt;- as_tibble(mc3_data$nodes) %&gt;%\n  distinct()\n\nglimpse(mc3_nodes_raw)\n\n\nRows: 60,520\nColumns: 15\n$ type                &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organizatio…\n$ country             &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", …\n$ ProductServices     &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food…\n$ PointOfContact      &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertso…\n$ HeadOfOrg           &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules La…\n$ founding_date       &lt;chr&gt; \"1954-04-24T00:00:00\", \"2009-06-12T00:00:00\", \"202…\n$ revenue             &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, …\n$ TradeDescription    &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoc…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Cor…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic…\n$ id                  &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Ab…\n$ dob                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nmc3_nodes_raw have 15 columns but many of them seems to be of no use from a data analysis perspective of this portion such as TradeDescription, _last_edited_by, _last_edited_date, _date_added, _raw_source, _algorithm, dob. In addition, some data column seems to be in the wrong format such as founding_date which supposed to be in datetime instead of character\nTherefore, I will select from the raw file, columns that I think maybe of use for the data analysis and fix the issue with wrong data format using the code below and call the new data mc3_nodes,I also rename the type to nodes_type instead since both the nodes and links dataframes seems to have type as one of the column\n\n\nShow the code\nmc3_nodes &lt;- mc3_nodes_raw %&gt;%\n  mutate(founding_date = as.Date(founding_date),\n         country = as.character(country),\n         id = as.character(id),\n         ProductServices = as.character(ProductServices),\n         revenue = as.numeric(as.character(revenue)),\n         type = as.character(type),\n         HeadOfOrg = as.character(HeadOfOrg),\n         PointOfContact = as.character(PointOfContact)) %&gt;%\n  select(id, \n         founding_date, \n         country, \n         type, \n         revenue, \n         ProductServices, \n         HeadOfOrg,\n         PointOfContact) %&gt;%\n  rename(nodes_type = type)\n\nglimpse(mc3_nodes)\n\n\nRows: 60,520\nColumns: 8\n$ id              &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Abbott…\n$ founding_date   &lt;date&gt; 1954-04-24, 2009-06-12, 2029-12-15, 1972-02-16, 1954-…\n$ country         &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", \"Oce…\n$ nodes_type      &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organization.Co…\n$ revenue         &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, 1696…\n$ ProductServices &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food pro…\n$ HeadOfOrg       &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules Labbé\"…\n$ PointOfContact  &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertson\", …\n\n\nThe founding_date is now in the correct format"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dataframe-links",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dataframe-links",
    "title": "Take-home Exercise 3",
    "section": "3. Dataframe links",
    "text": "3. Dataframe links\nFirst I import this nodes data using as_tibble() function and have a quick glimpse() at the data itself, let call this data mc3_edges_raw\n\n\nShow the code\nmc3_edges_raw &lt;- as_tibble(mc3_data$links) %&gt;%\n  distinct()\n\nglimpse(mc3_edges_raw)\n\n\nRows: 75,817\nColumns: 11\n$ start_date          &lt;chr&gt; \"2016-10-29T00:00:00\", \"2035-06-03T00:00:00\", \"202…\n$ type                &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Sharehol…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pela…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corp…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Imp…\n$ source              &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowm…\n$ target              &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and…\n$ key                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nmc3_edges_raw is also having the same prolem as mc3_nodes_raw of having 1 columns but many of them seems to be of no use from a data analysis perspective of this portion such as _last_edited_by, _last_edited_date, _date_added, _raw_source, _algorithm, key. In addition, some data column seems to be in the wrong format such as start_date and end_date which supposed to be in datetime instead of character\nTherefore, I will select from the raw file, columns that I think maybe of use for the data analysis and fix the issue with wrong data format using the code below and call the new data mc3_edges\n\n\nShow the code\nmc3_edges &lt;- mc3_edges_raw %&gt;%\n  select(source, \n         target, \n         type, \n         start_date, \n         end_date) %&gt;%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type),\n         start_date = as.Date(start_date),\n         end_date = as.Date(end_date)) \n\nglimpse(mc3_edges)\n\n\nRows: 75,817\nColumns: 5\n$ source     &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowman-Howe\",…\n$ target     &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and Downs\", …\n$ type       &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Shareholdership\",…\n$ start_date &lt;date&gt; 2016-10-29, 2035-06-03, 2028-11-20, 2024-09-04, 2034-11-12…\n$ end_date   &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nThe start_date and end_date are now in the correct format"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#number-of-organization-over-the-year.",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#number-of-organization-over-the-year.",
    "title": "Take-home Exercise 3",
    "section": "1. Number of Organization over the year.",
    "text": "1. Number of Organization over the year.\nFor this Analysis and visualization I want to create a time series line graph of how many organization were founded each year over the years, to find if there any trend or suspicious changes in number of Organization over the years.\nLet us look at the different type that the mc3_nodes data have\n\n\nShow the code\nunique(mc3_nodes$nodes_type)\n\n\n[1] \"Entity.Organization.Company\"         \n[2] \"Entity.Organization.LogisticsCompany\"\n[3] \"Entity.Organization.FishingCompany\"  \n[4] \"Entity.Organization.FinancialCompany\"\n[5] \"Entity.Organization.NewsCompany\"     \n[6] \"Entity.Organization.NGO\"             \n[7] \"Entity.Person\"                       \n[8] \"Entity.Person.CEO\"                   \n\n\nThere seems to be multiple type including Organization and Person, for the purpose of this analysis, we will be focusing on Organization. Therefore, I will filter the data to Organization. In addition, since the duration of founding_date is between 1945 to 2035 (70 years of data), I will create another column called founding_year to breakdown the date to year instead\n\n\nShow the code\nmc3_nodes_Organization &lt;- mc3_nodes %&gt;%\n  mutate(founding_year = format(founding_date, format=\"%Y\")) %&gt;%\n  filter(str_like(nodes_type, \"%Entity.Organization%\"))\nglimpse(mc3_nodes_Organization)\n\n\nRows: 8,871\nColumns: 9\n$ id              &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Abbott…\n$ founding_date   &lt;date&gt; 1954-04-24, 2009-06-12, 2029-12-15, 1972-02-16, 1954-…\n$ country         &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", \"Oce…\n$ nodes_type      &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organization.Co…\n$ revenue         &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, 1696…\n$ ProductServices &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food pro…\n$ HeadOfOrg       &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules Labbé\"…\n$ PointOfContact  &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertson\", …\n$ founding_year   &lt;chr&gt; \"1954\", \"2009\", \"2029\", \"1972\", \"1954\", \"2031\", \"2007\"…\n\n\nNext I would want to count the number of company founded per year using the code below under Organization_historical_year\n\n\nShow the code\nOrganization_historical_year &lt;- mc3_nodes_Organization %&gt;%\n  group_by(`founding_year`, `nodes_type`) %&gt;%\n  summarise(count = n())\n\n\nNext I will pivot_wider() the data so each different Organization counts would be in its own columns, this is for the purpose of plotting the graph later since I want to show them in the same plot as well as being able to select the specific Organization viewers want to choose. In addition, since I want to have a data table later showing the raw data I will also renaming the column to a more user friendly name and then sort the full table starting with the earliest year. This would create Organization_historical_year_select\n\n\nShow the code\nOrganization_historical_year_select &lt;- Organization_historical_year %&gt;%\n  select(founding_year, nodes_type, count) %&gt;%\n  pivot_wider(names_from = nodes_type, values_from = count) %&gt;%\n  rename(`Founding Year` = founding_year,\n         `Company` = Entity.Organization.Company,\n         `Fishing Company` = Entity.Organization.FishingCompany,\n         `Logistics Company` = Entity.Organization.LogisticsCompany,\n         `Financial Company` = Entity.Organization.FinancialCompany,\n         `News Company` = Entity.Organization.NewsCompany,\n         `NGO` = Entity.Organization.NGO)\n\nOrganization_historical_year_select &lt;- \n  Organization_historical_year_select[\n    order(Organization_historical_year_select$`Founding Year`),]\n\n\nWith that done, I would showcase final data table and plot the interactive time series graph with a time slider\n\n\nShow the code\ndatatable(Organization_historical_year_select, \n              filter = 'top', \n              options = list(pageLength = 10, \n                             autoWidth = TRUE))\n\n\n\n\n\n\n\nShow the code\nplot_ly(as.data.frame(Organization_historical_year_select),\n          x = ~`Founding Year`,\n          y = ~`Company`,\n          name = \"Company\",\n          type = 'scatter',\n          mode = 'lines+markers',\n          text = ~paste(\"Year: \", `Founding Year`, \n                        \"&lt;br&gt;Founded: \", Company),\n          hoverinfo = 'text') %&gt;%\n  add_trace(y = ~`Fishing Company`, \n            name = 'Fishing Company', \n            mode = 'lines+markers',\n            text = ~paste(\"Year: \", `Founding Year`,\n                          \"&lt;br&gt;Founded: \", `Fishing Company`),\n            hoverinfo = 'text') %&gt;%\n  add_trace(y = ~`Logistics Company`, \n            name = 'Logistics Company', \n            mode = 'lines+markers',\n            text = ~paste(\"Year: \", `Founding Year`,\n                          \"&lt;br&gt;Founded: \", `Logistics Company`),\n            hoverinfo = 'text') %&gt;%\n  add_trace(y = ~`Financial Company`, \n            name = 'Financial Company', \n            mode = 'lines+markers',\n            text = ~paste(\"Year: \", `Founding Year`,\n                          \"&lt;br&gt;Founded: \", `Financial Company`),\n            hoverinfo = 'text') %&gt;%\n  add_trace(y = ~`News Company`, \n            name = 'News Company', \n            mode = 'lines+markers',\n            text = ~paste(\"Year: \", `Founding Year`,\n                          \"&lt;br&gt;Founded: \", `News Company`),\n            hoverinfo = 'text') %&gt;%\n  add_trace(y = ~`NGO`, \n            name = 'NGO', \n            mode = 'lines+markers',\n            text = ~paste(\"Year: \", `Founding Year`,\n                          \"&lt;br&gt;Founded: \", `NGO`),\n            hoverinfo = 'text') %&gt;%\n  layout(legend = list(orientation = 'h'),\n         xaxis = list(title = \"Founding Year\", \n                      rangeslider = list(visible = TRUE, \n                                         thickness = 0.03)),\n         yaxis = list(title = \"Count\"))\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThere seems to be a spike of number of Company founded between 2034 and 2035, the number of Fishing Company has a spike in 2031 but has been since on a steady decline ever since."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#beneficial-ownership-data-analysis-and-visualization",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#beneficial-ownership-data-analysis-and-visualization",
    "title": "Take-home Exercise 3",
    "section": "2. Beneficial Ownership data analysis and Visualization",
    "text": "2. Beneficial Ownership data analysis and Visualization\nLet looks at the different of relationship type that the mc3_edges table has\n\n\nShow the code\nunique(mc3_edges$type)\n\n\n[1] \"Event.Owns.Shareholdership\"      \"Event.Owns.BeneficialOwnership\" \n[3] \"Event.WorksFor\"                  \"Relationship.FamilyRelationship\"\n\n\nThere seems to be 4 type of relationship, for this part I would be focusing more on the Beneficial Ownership relationship. First thing first, as previously seen there seems to be 2 columns that represent the entity relation either source or target. I am curious to see what are the type of the entity for each of these source and target hence I would use the mc3_nodes to join with mc3_edges table to find out the nature of these source or target\n\n\nShow the code\nnodes_type &lt;- mc3_nodes %&gt;%\n  select(id, nodes_type)\n\nmc3_edges &lt;- mc3_edges %&gt;%\n  left_join(nodes_type, by = c(\"source\" = \"id\")) %&gt;%\n  rename(nodes_type_source = nodes_type) %&gt;%\n  left_join(nodes_type, by = c(\"target\" = \"id\")) %&gt;%\n  rename(nodes_type_target = nodes_type)\n\n\nLet us check the data generated\n\n\nShow the code\nmc3_edges %&gt;%\n  filter(type == \"Event.Owns.BeneficialOwnership\") %&gt;%\n  head()\n\n\n# A tibble: 6 × 7\n  source  target type  start_date end_date nodes_type_source nodes_type_target  \n  &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;     &lt;date&gt;   &lt;chr&gt;             &lt;chr&gt;              \n1 Laura … Brigg… Even… 2018-05-10 NA       Entity.Person     Entity.Organizatio…\n2 Jillia… Brigg… Even… 2013-11-30 NA       Entity.Person     Entity.Organizatio…\n3 Anna B… Brigg… Even… 2012-05-04 NA       Entity.Person     Entity.Organizatio…\n4 Dawn K… Brigg… Even… 2007-03-16 NA       Entity.Person     Entity.Organizatio…\n5 Dawn K… Flemi… Even… 2016-09-28 NA       Entity.Person     Entity.Organizatio…\n6 Elizab… Brigg… Even… 2011-11-28 NA       Entity.Person     Entity.Organizatio…\n\n\nInterestingly, it seems like source are the entity that has the type relationship with the target, on the Beneficial Ownership context, source are the owners (specifically person or individual) and target is the one being owned (specifically Organization).\nWith the understanding above I want find out want to know how many in total a source own a target and how many source (owners) a target have over the year. Let us start with the first part\n\nHow many in total a source own a target over the year\nFor this part I will first filter the data to Event.Owns.BeneficialOwnership then do a group_by() of start_date and source then count the number of row creating BO_indv_count. Afteward, I will group_by() again using source and sum the BO_indv_count creating the cummulative column BO_indv_total\n\n\nShow the code\nedges_BO_indv_count &lt;- mc3_edges %&gt;%\n  filter(type == \"Event.Owns.BeneficialOwnership\") %&gt;%\n  group_by(start_date, source) %&gt;%  \n  summarise(BO_indv_count = n())%&gt;%\n  group_by(source) %&gt;%\n  mutate(BO_indv_total = cumsum(BO_indv_count)) %&gt;%\n  ungroup()\n\n\nLet see how many unique source there is in the table\n\nn_distinct(edges_BO_indv_count$source)\n\n[1] 16231\n\n\n16231 is quite a large number, hence I will reduce this number by create a list of Owner that own 10 or more target using the code below\n\n\nShow the code\nOwner_list &lt;- \n  edges_BO_indv_count[\n    order(edges_BO_indv_count$BO_indv_total,\n          decreasing = T),] %&gt;%\n  filter(BO_indv_total&gt;=10) %&gt;%\n  select(source) %&gt;%\n  distinct()\n\n\nWhat left now is to plot the graph showing the Individual total Beneficial Ownership over time\n\n\nShow the code\nBO_indv_count_table &lt;- edges_BO_indv_count %&gt;%\n  rename(`Start Date` = start_date,\n         `Individual` = source,\n         `Ownership at curent date` = BO_indv_count,\n         `Total Ownership at curent date` = BO_indv_total)\n  \ndatatable(BO_indv_count_table, \n              filter = 'top', \n              options = list(pageLength = 10, \n                             autoWidth = TRUE))\n\n\n\n\n\n\n\nShow the code\nfig &lt;- edges_BO_indv_count %&gt;%\n  select(start_date, source, BO_indv_total) %&gt;%\n  filter(source %in% Owner_list$source)%&gt;%\n  plot_ly(x = ~start_date,\n          y = ~BO_indv_total,\n          type = 'scatter',\n          mode = 'lines+markers',\n          text = ~paste(\"Day: \", start_date, \n                        \"&lt;br&gt;Own: \", BO_indv_total),\n          hoverinfo = 'text',\n          fill = 'tozeroy',\n          transforms = list(\n            list(\n              type = 'filter',\n              target = ~source,\n              operation = '=',\n              value = unique(Owner_list$source)[1]))) %&gt;%\n  layout(title = 'Individual total Beneficial Ownership over time',\n         xaxis = list(title = \"Time\",\n                      rangeslider = list(visible = TRUE,\n                                         thickness = 0.03)),\n         yaxis = list(title = \"Count\"),\n         updatemenus = list(\n           list(type = 'dropdown',\n                active = 0,\n                buttons = list(\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[1]),\n                       label = unique(Owner_list$source)[1]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[2]),\n                       label = unique(Owner_list$source)[2]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[3]),\n                       label = unique(Owner_list$source)[3]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[4]),\n                       label = unique(Owner_list$source)[4]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[5]),\n                       label = unique(Owner_list$source)[5]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[6]),\n                       label = unique(Owner_list$source)[6]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[7]),\n                       label = unique(Owner_list$source)[7]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[8]),\n                       label = unique(Owner_list$source)[8]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[9]),\n                       label = unique(Owner_list$source)[9]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[10]),\n                       label = unique(Owner_list$source)[10]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[11]),\n                       label = unique(Owner_list$source)[11]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[12]),\n                       label = unique(Owner_list$source)[12]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[13]),\n                       label = unique(Owner_list$source)[13]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[14]),\n                       label = unique(Owner_list$source)[14]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[15]),\n                       label = unique(Owner_list$source)[15]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[16]),\n                       label = unique(Owner_list$source)[16]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[17]),\n                       label = unique(Owner_list$source)[17]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[18]),\n                       label = unique(Owner_list$source)[18]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[19]),\n                       label = unique(Owner_list$source)[19]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[20]),\n                       label = unique(Owner_list$source)[20]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[21]),\n                       label = unique(Owner_list$source)[21]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[22]),\n                       label = unique(Owner_list$source)[22]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[23]),\n                       label = unique(Owner_list$source)[23]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[24]),\n                       label = unique(Owner_list$source)[24]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[25]),\n                       label = unique(Owner_list$source)[25]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[26]),\n                       label = unique(Owner_list$source)[26]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[27]),\n                       label = unique(Owner_list$source)[27]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[28]),\n                       label = unique(Owner_list$source)[28]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[29]),\n                       label = unique(Owner_list$source)[29]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[30]),\n                       label = unique(Owner_list$source)[30]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[31]),\n                       label = unique(Owner_list$source)[31]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[32]),\n                       label = unique(Owner_list$source)[32]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[33]),\n                       label = unique(Owner_list$source)[33]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[34]),\n                       label = unique(Owner_list$source)[34]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[35]),\n                       label = unique(Owner_list$source)[35]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[36]),\n                       label = unique(Owner_list$source)[36]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Owner_list$source)[37]),\n                       label = unique(Owner_list$source)[37])\n                  )\n                )\n              )\n            )\n\nfig\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThere seems to be a few individual of interest such as Zachary Taylor or Breanna Price who suddenly start owning a significant amount of entities between 2033 and 2034 but then slow down their activities in 2035\n\n\n\n\nHow many in total target owned by source over the year\nSame as before I will go through the data creation steps\n\n\nShow the code\nBO_owners_count &lt;- mc3_edges %&gt;%\n  filter(type == \"Event.Owns.BeneficialOwnership\") %&gt;%\n  group_by(start_date, target) %&gt;%  \n  summarise(BeneficialOwnership_count = n())%&gt;%\n  group_by(target) %&gt;%\n  mutate(BeneficialOwnership_total = cumsum(BeneficialOwnership_count)) %&gt;%\n  ungroup()\n\n\nCompany that has 35 or more source using the code below\n\n\nShow the code\nCompany_list &lt;- \n  BO_owners_count[\n    order(BO_owners_count$BeneficialOwnership_total,\n          decreasing = T),] %&gt;%\n  filter(BeneficialOwnership_total&gt;=35) %&gt;%\n  select(target) %&gt;%\n  distinct()\n\n\nAnd finally plotting\n\n\nShow the code\nBO_owners_count_table &lt;- BO_owners_count %&gt;%\n  rename(`Start Date` = start_date,\n         `Organization` = target,\n         `New owners at curent date` = BeneficialOwnership_count,\n         `Total owners at curent date` = BeneficialOwnership_total)\n  \ndatatable(BO_owners_count_table, \n              filter = 'top', \n              options = list(pageLength = 10, \n                             autoWidth = TRUE))\n\n\n\n\n\n\n\nShow the code\nfig1 &lt;- BO_owners_count %&gt;%\n  select(start_date, target, BeneficialOwnership_total) %&gt;%\n  filter(target %in% Company_list$target)%&gt;%\n  plot_ly(x = ~start_date,\n          y = ~BeneficialOwnership_total,\n          type = 'scatter',\n          mode = 'lines+markers',\n          text = ~paste(\"Day: \", start_date, \n                        \"&lt;br&gt;Owner: \", BeneficialOwnership_total),\n          hoverinfo = 'text',\n          fill = 'tozeroy',\n          transforms = list(\n            list(\n              type = 'filter',\n              target = ~target,\n              operation = '=',\n              value = unique(Company_list$target)[1]))) %&gt;%\n  layout(title = 'Company total number of Beneficial Owners over time',\n         xaxis = list(title = \"Time\",\n                      rangeslider = list(visible = TRUE,\n                                         thickness = 0.03)),\n         yaxis = list(title = \"Count\"),\n         updatemenus = list(\n           list(type = 'dropdown',\n                active = 0,\n                buttons = list(\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[1]),\n                       label = unique(Company_list$target)[1]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[2]),\n                       label = unique(Company_list$target)[2]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[3]),\n                       label = unique(Company_list$target)[3]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[4]),\n                       label = unique(Company_list$target)[4]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[5]),\n                       label = unique(Company_list$target)[5]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[6]),\n                       label = unique(Company_list$target)[6]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[7]),\n                       label = unique(Company_list$target)[7]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[8]),\n                       label = unique(Company_list$target)[8]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[9]),\n                       label = unique(Company_list$target)[9]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[10]),\n                       label = unique(Company_list$target)[10]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[11]),\n                       label = unique(Company_list$target)[11]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[12]),\n                       label = unique(Company_list$target)[12]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[13]),\n                       label = unique(Company_list$target)[13]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[14]),\n                       label = unique(Company_list$target)[14]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[15]),\n                       label = unique(Company_list$target)[15]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[16]),\n                       label = unique(Company_list$target)[16]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[17]),\n                       label = unique(Company_list$target)[17]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[18]),\n                       label = unique(Company_list$target)[18]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[19]),\n                       label = unique(Company_list$target)[19]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[20]),\n                       label = unique(Company_list$target)[20]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[21]),\n                       label = unique(Company_list$target)[21]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[22]),\n                       label = unique(Company_list$target)[22]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[23]),\n                       label = unique(Company_list$target)[23]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[24]),\n                       label = unique(Company_list$target)[24]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[25]),\n                       label = unique(Company_list$target)[25]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[26]),\n                       label = unique(Company_list$target)[26]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[27]),\n                       label = unique(Company_list$target)[27]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[28]),\n                       label = unique(Company_list$target)[28]),\n                  list(method = \"restyle\",\n                       args = list(\"transforms[0].value\",\n                                   unique(Company_list$target)[29]),\n                       label = unique(Company_list$target)[29])\n                  )\n                )\n              )\n            )\nfig1\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThere seems to be a few company of interest such as Downs Group who suddenly start having their business under owner ship at a significant rate between 2034 and 2035"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html",
    "title": "Hands-on Exercise 9.1 Creating Ternary Plot with R",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html#the-data",
    "title": "Hands-on Exercise 9.1 Creating Ternary Plot with R",
    "section": "3.1 The data",
    "text": "3.1 The data\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html#importing-data",
    "title": "Hands-on Exercise 9.1 Creating Ternary Plot with R",
    "section": "3.2 Importing Data",
    "text": "3.2 Importing Data\nTo import respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html#preparing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html#preparing-the-data",
    "title": "Hands-on Exercise 9.1 Creating Ternary Plot with R",
    "section": "3.3 Preparing the Data",
    "text": "3.3 Preparing the Data\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year)) %&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8])) %&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018) %&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html#plotting-a-static-ternary-diagram",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html#plotting-a-static-ternary-diagram",
    "title": "Hands-on Exercise 9.1 Creating Ternary Plot with R",
    "section": "4.1 Plotting a static ternary diagram",
    "text": "4.1 Plotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html#plotting-an-interative-ternary-diagram",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.1.html#plotting-an-interative-ternary-diagram",
    "title": "Hands-on Exercise 9.1 Creating Ternary Plot with R",
    "section": "4.2 Plotting an interative ternary diagram",
    "text": "4.2 Plotting an interative ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\nlabel &lt;- function(txt) {\n  list(text = txt,\n       x = 0.1, y = 1,\n       ax = 0, ay = 0,\n       xref = \"paper\",\n       yref = \"paper\",\n       align = \"center\",\n       font = list(family = \"serif\",\n                   size = 15,\n                   color = \"white\"),\n       bgcolor = \"#b3b3b3\",\n       bordercolor = \"black\",\n       borderwidth = 2)\n}\n\n\naxis &lt;- function(txt) {\n  list(title = txt, \n       tickformat = \".0%\", \n       tickfont = list(size = 10))\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n\nplot_ly(agpop_mutated,\n        a = ~YOUNG,\n        b = ~ACTIVE,\n        c = ~OLD,\n        color = I(\"black\"),\n        type = \"scatterternary\") %&gt;%\n  layout(annotations = label(\"Ternary Markers\"),\n         ternary = ternaryAxes)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\nRendering the value of a correlation to depict its sign and magnitude, and Reordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception. In this hands-on exercise, we will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, we will learn how to create correlation matrix using pairs() of R Graphics. Next, we will learn how to plot corrgram using corrplot package of R. Lastly, we will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#building-a-basic-correlation-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#building-a-basic-correlation-matrix",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "4.1 Building a basic correlation matrix",
    "text": "4.1 Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphate and alcohol.\n\npairs(wine[,2:12])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#drawing-the-lower-corner",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#drawing-the-lower-corner",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "4.2 Drawing the lower corner",
    "text": "4.2 Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\nSimilarly, we can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#including-with-correlation-coefficients",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#including-with-correlation-coefficients",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "4.3 Including with correlation coefficients",
    "text": "4.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\n\non.exit(par(usr))\n\npar(usr = c(0, 1, 0, 1))\n\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\n\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, \n             txt, \n             sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#the-basic-plot",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#the-basic-plot",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "The basic plot",
    "text": "The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(data = wine,\n                       cor.vars = 1:11)\n\n\n\n\n\nggstatsplot::ggcorrmat(data = wine,\n                       cor.vars = 1:11,\n                       ggcorrplot.args = list(outline.color = \"black\",\n                                              hc.order = TRUE,\n                                              tl.cex = 10),\n                       title    = \"Correlogram for wine dataset\",\n                       subtitle = \"Four pairs are no significant at p &lt; 0.05\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\n\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(theme(text=element_text(size=5),\n                              axis.text.x = element_text(size = 8),\n                              axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#getting-started-with-corrplot",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#getting-started-with-corrplot",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "7.1 Getting started with corrplot",
    "text": "7.1 Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#working-with-visual-geometrics",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#working-with-visual-geometrics",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "7.2 Working with visual geometrics",
    "text": "7.2 Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"square\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#working-with-layout",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#working-with-layout",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "7.3 Working with layout",
    "text": "7.3 Working with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#working-with-mixed-layout",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#working-with-mixed-layout",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "7.4 Working with mixed layout",
    "text": "7.4 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#combining-corrgram-with-the-significant-test",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#combining-corrgram-with-the-significant-test",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "7.5 Combining corrgram with the significant test",
    "text": "7.5 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .9)\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .1)\n\n\n\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#reorder-a-corrgram",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#reorder-a-corrgram",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "7.6 Reorder a corrgram",
    "text": "7.6 Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n  “hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n“alphabet” for alphabetical order. “AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#reordering-a-correlation-matrix-using-hclust",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#reordering-a-correlation-matrix-using-hclust",
    "title": "Hands-on Exercise 9.2 Visual Correlation Analysis",
    "section": "7.7 Reordering a correlation matrix using hclust",
    "text": "7.7 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, we will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#importing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#importing-the-data-set",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "3.1 Importing the data set",
    "text": "3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format. The output tibbled data frame is called wh\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#preparing-the-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#preparing-the-data-1",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "3.2 Preparing the data",
    "text": "3.2 Preparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#transforming-the-data-frame-into-a-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#transforming-the-data-frame-into-a-matrix",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "3.3 Transforming the data frame into a matrix",
    "text": "3.3 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#heatmap-of-r-stats",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#heatmap-of-r-stats",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.1 heatmap() of R Stats",
    "text": "4.1 heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, \n                      Colv=NA)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5. Creating Interactive Heatmap",
    "text": "5. Creating Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manual of the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#working-with-heatmaply",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#working-with-heatmaply",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5.1 Working with heatmaply",
    "text": "5.1 Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#data-trasformation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#data-trasformation",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5.2 Data trasformation",
    "text": "5.2 Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n5.2.1 Scaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columnwise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n5.2.2 Normalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n5.2.3 Percentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#clustering-algorithm",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5.3 Clustering algorithm",
    "text": "5.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#manual-approach",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#manual-approach",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5.4 Manual approach",
    "text": "5.4 Manual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#statistical-approach",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#statistical-approach",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5.5 Statistical approach",
    "text": "5.5 Statistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, \n                   method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#seriation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#seriation",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5.6 Seriation",
    "text": "5.6 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#working-with-colour-palettes",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#working-with-colour-palettes",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5.7 Working with colour palettes",
    "text": "5.7 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#the-finishing-touch",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.3.html#the-finishing-touch",
    "title": "Hands-on Exercise 9.3 Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5.8 The finishing touch",
    "text": "5.8 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,300, 40,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018\n          DataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html",
    "title": "Hands-on Exercise 9.4 Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#plotting-a-simple-parallel-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#plotting-a-simple-parallel-coordinates",
    "title": "Hands-on Exercise 9.4 Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "4.1 Plotting a simple parallel coordinates",
    "text": "4.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#plotting-a-parallel-coordinates-with-boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#plotting-a-parallel-coordinates-with-boxplot",
    "title": "Hands-on Exercise 9.4 Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "4.2 Plotting a parallel coordinates with boxplot",
    "text": "4.2 Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\n\n\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#parallel-coordinates-with-facet",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#parallel-coordinates-with-facet",
    "title": "Hands-on Exercise 9.4 Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "4.3 Parallel coordinates with facet",
    "text": "4.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#the-basic-plot",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#the-basic-plot",
    "title": "Hands-on Exercise 9.4 Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "5.1 The basic plot",
    "text": "5.1 The basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\n\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#rotate-axis-label",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#rotate-axis-label",
    "title": "Hands-on Exercise 9.4 Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "5.2 Rotate axis label",
    "text": "5.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#changing-the-colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#changing-the-colour-scheme",
    "title": "Hands-on Exercise 9.4 Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "5.3 Changing the colour scheme",
    "text": "5.3 Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#parallel-coordinates-plot-with-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.4.html#parallel-coordinates-plot-with-histogram",
    "title": "Hands-on Exercise 9.4 Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "5.4 Parallel coordinates plot with histogram",
    "text": "5.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  }
]